{"meta":{"title":"Tianlong Chen (陈天龙)","subtitle":"What does not kill you makes you stronger","description":"Make the change that you want to see in the world","author":"Tianlong Chen (陈天龙)","url":"https://Tianlong-Chen.github.io","root":"/"},"pages":[{"title":"Hello World!","date":"2022-09-30T22:22:01.751Z","updated":"2022-09-30T22:22:01.745Z","comments":true,"path":"about/index.html","permalink":"https://tianlong-chen.github.io/about/index.html","excerpt":"","text":"I am currently a fourth-year Ph.D. candidate of Electrical and Computer Engineering (DICE) at VITA, The University of Texas at Austin, advised by Dr. Zhangyang (Atlas) Wang. My research interests include Sparse Neural Network &amp; Lottery Ticket Hypothesis, AutoML &amp; Learning to Optimize, Adversarial Robustness, Graph Neural Networks, and Self-Supervision. I am a recipient of 2021 IBM Ph.D. Fellowship, 2021 Graduate Dean’s Prestigious Fellowship, 2022 Adobe Ph.D. Fellowship. [Resume] [Google Scholar] [Publication] Education [Aug. 2020 - Present] Ph.D. candidate in Electrical and Computer Engineering, DICE, The University of Texas at Austin [Aug. 2018 - Aug. 2020] Ph.D. student in Computer Science, Texas A&amp;M University [Aug. 2013 - Jun. 2017] B.S.c. in Applied Mathematics and B.Eng. (Dual) in Computer Science, School of the Gifted Young, University of Science and Technology of China Selected Conference Paper[*equal contribution] 2022[NeurIPS’22] M3ViT: Mixture-of-Experts Vision Transformer for Efficient Multi-task Learning with Model-Accelerator Co-designH. Liang, Z. Fan, R. Sarkar, Z. Jiang, T. Chen, K. Zou, Y. Cheng, C. Hao, and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’22] Randomized Channel Shuffling: Minimal-Overhead Backdoor Attack Detection without Clean DatasetsR. Cai, Z. Zhang, T. Chen, X. Chen, and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’22] Old can be Gold: Better Gradient Flow can make Vanilla-GCNs Great AgainA. Jaiswal, P. Wang, T. Chen, J. Rousseau, Y. Ding, and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’22] Sparse Winning Tickets are Data-Efficient Image RecognizersM. Varma, X. Chen, Z. Zhang, T. Chen, S. Venugopalan, and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’22] Augmentations in Hypergraph Contrastive Learning: Fabricated and GenerativeT. Wei, Y. You, T. Chen, Y. Shen, J. He, and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’22] Advancing Model Pruning via Bi-level OptimizationY. Zhang, Y. Yao, P. Ram, P. Zhao, T. Chen, M. Hong, Y. Wang, S. Liu. [Paper] [Code] [Abstract] [NeurIPS’22 Dataset and Benchmark] A Comprehensive Study on Large-Scale Graph Training: Benchmarking and RethinkingK. Duan, Z. Liu, P. Wang, W. Zheng, K. Zhou, T. Chen, X. Hu, and Z. Wang. [Paper] [Code] [Abstract] [ECCV’22] Scalable Learning to Optimize: A Learned Optimizer Can Train Big ModelsX. Chen*, T. Chen*, Y. Cheng, W. Chen, A. Awadallah, and Z. Wang. [Paper] [Code] [Abstract] [ECCV’22] DnA: Improving Few-shot Transfer Learning with Low-Rank Decomposition and AlignmentZ. Jiang, T. Chen, X. Chen, Y. Cheng, L. Zhou, L. Yuan, A. Awadallah, and Z. Wang. [Paper] [Code] [Abstract] [ECCV’22] Point Cloud Domain Adaptation via Masked Local 3D Structure PredictionH. Liang, H. Fan, Z. Fan, Y. Wang, T. Chen, Y. Cheng, and Z. Wang. [Paper] [Code] [Abstract] [ICML’22] Data-Efficient Double-Win Lottery Tickets from Robust Pre-trainingT. Chen, Z. Zhang, S. Liu, Y. Zhang, S. Chang, and Z. Wang. [Paper] [Code] [Abstract] [ICML’22] Coarsening the Granularity: Towards Structurally Sparse Lottery TicketsT. Chen, X. Chen, X. Ma, Y. Wang, and Z. Wang. [Paper] [Code] [Abstract] [ICML’22] Linearity Grafting: How Neuron Pruning Helps Certifiable RobustnessT. Chen*, H. Zhang*, Z. Zhang, S. Chang, S. Liu, P. Chen, and Z. Wang. [Paper] [Code] [Abstract] [ICML22] Universality of Winning Tickets: A Renormalization Group PerspectiveW. Redman, T. Chen, Z. Wang, and A. Dogra. [Paper] [Code] [Abstract] [ICML’22] Training Your Sparse Neural Network Better with Any MaskA. Jaiswal, H. Ma, T. Chen, Y. Ding, and Z. Wang. [Paper] [Code] [Abstract] [ICML’22] Neural Implicit Dictionary Learning via Mixture-of-Expert TrainingP. Wang, Z. Fan, T. Chen, and Z. Wang. [Paper] [Code] [Abstract] [CVPR22] The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of RedundancyT. Chen, Z. Zhang, Y. Chang, A. Awadallah, and Z. Wang. [Paper] [Code] [Abstract] [CVPR’22] Aug-NeRF: Training Stronger Neural Radiance Fields with Triple-Level AugmentationsT. Chen*, P. Wang*, Z. Fan, and Z. Wang. [Paper] [Code] [Abstract] [CVPR’22] Quarantine: Sparsity Can Uncover the Trojan Attack Trigger for FreeT. Chen*, Z. Zhang*, Y. Zhang*, S. Chang, S. Liu, and Z. Wang. [Paper] [Code] [Abstract] [CVPR’22 Oral] CADTransformer: Panoptic Symbol Spotting Transformer for CAD DrawingsZ. Fan, T. Chen, P. Wang, and Z. Wang. [Paper] [Code] [Abstract] [ICLR‘22] Sparsity Winning Twice: Better Robust Generalization from More Efficient TrainingT. Chen*, Z. Zhang*, P. Wang*, S. Balachandra*, H. Ma*, Z. Wang and Z. Wang. [Paper] [Code] [Abstract] [ICLR’22] Unified Visual Transformer CompressionS. Xing*, T. Chen*, J. Shen, H. Yuan, J. Tan, S. Yang, J. Liu and Z. Wang. [Paper] [Code] [Abstract] [ICLR’22] Audio Lottery: Speech Recognition Made Ultra-Li- ghtweight, Noise-Robust, and TransferableS. Ding*, T.Chen* and Z. Wang. [Paper] [Code] [Abstract] [ICLR’22 Spotlight] Learning Pruning-Friendly Networks via Frank-Wolfe: One-Shot, Any-Sparsity, And No RetrainingL. Miao, X. Luo, T. Chen, W. Chen, D. Liu and Z. Wang. [Paper] [Code] [Abstract] [ICLR’22] The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse TrainingS. Liu, T. Chen, X. Chen, L. Shen, D. Mocanu, Z. Wang and M. Pechenizkiy. [Paper] [Code] [Abstract] [ICLR’22] Deep Ensembling with No Overhead for either Training or Testing: The All-Round B- lessings of Dynamic SparsityS. Liu, T. Chen, Z. Atashgahi, X. Chen, G. Sokar, E. Mocanu, M. Pechenizkiy, Z. Wang and D. Mocanu. [Paper] [Code] [Abstract] [ICLR’22] Scaling the Depth of Vision Transformers via the Fourier Domain AnalysisP. Wang, W. Zheng, T. Chen and Z. Wang. [Paper] [Code] [Abstract] [ICLR’22] Symbolic Learning to Optimize: Towards Interpretability and ScalabilityW. Zheng, T. Chen, T. Hu and Z. Wang. [Paper] [Code] [Abstract] [ICLR’22] Optimizer AmalgamationT. Huang, T. Chen, S. Liu, S. Chang, L. Amini and Z. Wang. [Paper] [Code] [Abstract] [ICLR’22] Bayesian Modeling and Uncertainty Quantification for Learning to Optimize: What, Why, and HowY. You, Y. Cao, T. Chen, Z. Wang and Y. Shen. [Paper] [Code] [Abstract] [AutoML’22] AutoCoG: A Unified Data-Model Co-Search Framework for Graph Neural NetworksD. Hoang, K. Zhou, T. Chen, X. Hu, and Z. Wang. [Paper] [Code] [Abstract] [AAAI’22] Playing Lottery Tickets with Vision and LanguageZ. Gan, Y. Chen, L. Li, T. Chen, Y. Cheng, S. Wang and J. Liu. [Paper] [Code] [Abstract] [WSDM’22] Bringing Your Own View: Graph Contrastive Learning without Prefabricated Data Augmentations Y. You, T. Chen, Z. Wang and Y. Shen. [Paper] [Code] [Abstract] 2021 [NeurIPS’21] Chasing Sparsity in Vision Transformers: An End-to-End ExplorationT. Chen, Y. Cheng, Z. Gan, L. Yuan, L. Zhang and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’21] Data-Efficient GAN Training Beyond (Just) Augmentations: A Lottery Ticket Perspective T. Chen, Y. Cheng, Z. Gan, J. Liu, and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’21] You are caught stealing my winning lottery ticket! Making a lottery ticket claim its ownership X. Chen*, T. Chen*, Z. Zhang and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’21] Sparse Training via Boosting Pruning Plasticity with NeuroregenerationS. Liu, T. Chen, X. Chen, Z. Atashgahi, L. Yin, H. Kou, L. Shen, M. Pechenizkiy, Z. Wang, and D. Mocanu. [Paper] [Code] [Abstract] [NeurIPS’21] Improving Contrastive Learning on Imbalanced Data via Open-World SamplingZ. Jiang, T. Chen, T. Chen and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’21] Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot? X. Ma, G. Yuan, X. Shen, T. Chen, X. Chen, X. Chen, N. Liu, M. Qin, S. Liu, Z. Wang and Y. Wang. [Paper] [Code] [Abstract] [ICML’21] A Unified Lottery Ticket Hypothesis for Graph Neural NetworksT. Chen*, Y. Sui*, X. Chen, A. Zhang, and Z. Wang. [Paper] [Code] [Abstract] [ICML’21] Efficient Lottery Ticket Finding: Less Data is MoreZ. Zhang*, X. Chen*, T. Chen*, and Z. Wang. [Paper] [Code] [Abstract] [ICML’21 Long Talk] Graph Contrastive Learning AutomatedY. You, T. Chen, Y. Shen, and Z. Wang. [Paper] [Code] [Abstract] [ICML’21 Long Talk] Sparse and Imperceptible Adversarial Attack via a Homotopy AlgorithmM. Zhu, T. Chen, and Z. Wang. [Paper] [Code] [Abstract] [ICML’21] Self-Damaging Contrastive LearningZ. Jiang, T. Chen, B. Mortazavi, and Z. Wang. [Paper] [Code] [Abstract] [CVPR’21] The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer VisionT. Chen, J. Frankle, S. Chang, S. Liu, Y. Zhang, Z. Wang, and M. Carbin. [Paper] [Code] [Abstract] [Project] [CVPR’21] Troubleshooting Blind Image Quality Models in the WildZ. Wang, H. Wang, T. Chen, Z. Wang, and K. Ma. [Paper] [Code] [Abstract] [ICLR’21] Robust Overfitting may be mitigated by properly learned smootheningT. Chen*, Z. Zhang*, S. Liu, S. Chang, and Z. Wang. [Paper] [Code] [Abstract] [ICLR’21] Long Live the Lottery: The Existence of Winning Tickets in Lifelong LearningT. Chen*, Z. Zhang*, S. Liu, S. Chang, and Z. Wang. [Paper] [Code] [Abstract] [ICLR’21] GANs Can Play Lottery Tickets TooX. Chen, Z. Zhang, Y. Sui, and T. Chen. [Paper] [Code] [Abstract] [ICLR’21 Spotlight Oral] Undistillable: Making A Nasty Teacher That CANNOT teach studentsH. Ma, T. Chen, T. Hu, C. You, X. Xie, and Z. Wang. [Paper] [Code] [Abstract] [ICLR’21] Learning A Minimax Optimizer: A Pilot StudyJ. Shen, X. Chen, H. Heaton, T. Chen, J. Liu, W. Yin, and Z. Wang. [Paper] [Code] [Abstract] [CVPRW’21 Spotlight Oral] BNN-BN=? Training Binary Neural Networks without Batch Normalization T. Chen, Z. Zhang, X. Ouyang, Z. Liu, Z. Shen and Z. Wang. [Paper] [Code] [Abstract] [ICASSP’21] VGAI: End-to-End Learning of Vision-Based Decentralized Controllers for Robust SwarmsT. Hu, F. Gama, T. Chen, Z. Wang, A. Ribeiro, and B. Sadler. [Paper] [Code] [Abstract] [AAAIW’21 Oral] AR-Stock: Deep Augmented Relational Stock PredictionT. Wei, Y. You, and T. Chen. [Paper] [Code] [Abstract] 2020 [NeurIPS’20 Spotlight Oral] Training Stronger Baselines for Learning to OptimizeT. Chen*, W. Zhang*, J. Zhou, S. Chang, S. Liu, L. Amini, and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’20] The Lottery Ticket Hypothesis for Pre-trained BERT NetworksT. Chen, J. Frankle, S. Chang, S. Liu, Y. Zhang, Z. Wang, and M. Carbin. [Paper] [Code] [Abstract] [Project] [NeurIPS’20] Once-for-All Adversarial Training: In-Situ Trade off between Robustness and Accuracy for FreeH. Wang*, T. Chen*, S. Gui, T. Hu, J. Liu, and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’20] Graph Contrastive Learning with AugmentationsY. You*, T. Chen*, Y. Sui, T. Chen, Z. Wang, and S. Yang. [Paper] [Code] [Abstract] [NeurIPS’20] Robust Pre-Training by Adversarial Contrastive LearningZ. Jiang, T. Chen, T. Chen, and Z. Wang. [Paper] [Code] [Abstract] [InterSpeech’20] AutoSpeech: Neural Architecture Search for Speaker RecognitionS. Ding*, T. Chen*, X. Gong, W. Zha, and Z. Wang. [Paper] [Code] [Abstract] [ECCV’20] HALO: Hardware-Aware Learning to Optimize C. Li*, T. Chen*, H. You, Z. Wang, and Y. Lin. [Paper] [Code] [Abstract] [ICML’20] When Does Self-Supervision Help Graph Convolutional Networks?Y. You*, T. Chen*, Z. Wang, and Y. Shen. [Paper] [Code] [Abstract] [ICML’20] Self-PU: Self Boosted and Calibrated Positive-Unlabeled TrainingX. Chen, W. Chen, T. Chen, Y. Yuan, C. Gong, K. Chen, and Z. Wang. [Paper] [Code] [Abstract] [CVPR’20] Adversarial Robustness: From Self-Supervised Pre-Training to Fine-TuningT. Chen, S. Liu, S. Chang, Y. Cheng, L. Amini, and Z. Wang. [Paper] [Code] [Abstract] [CVPR’20] L^2-GCN: Layer-Wise and Learned Efficient Training of Graph Convolutional NetworksY. You*, T. Chen*, Z. Wang, and Y. Shen. [Paper] [Code] [Abstract] [ICLR’20] Triple Wins: Boosting Accuracy, Robustness and Efficiency by Enabling Input-Adaptive InferenceT. Hu*, T. Chen*, H. Wang, and Z. Wang. [Paper] [Code] [Abstract] [ICLR’20] I am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively H. Wang, T. Chen, Z. Wang, and K. Ma. [Paper] [Code] [Abstract] 2019 [NeurIPS’19] Learning to Optimize in SwarmsY. Cao, T. Chen, Z. Wang, and S. Yang. [Paper] [Code] [Abstract] [ICCV’19] ABD-Net: Attentive but Diverse Person Re-IdentificationT. Chen, S. Ding, J. Xie, Y. Yuan, W. Chen, Y. Yang, Z. Ren, and Z. Wang. [Paper] [Code] [Abstract] Selected Journal Paper [JMLR’22] Learning to Optimize: A Primer and A Benchmark(α-β) T. Chen, X. Chen, W. Chen, H. Heaton, J. Liu, Z. Wang, and W.Yin. [Paper] [Code] [Abstract] [TPAMI’22] Bag of Tricks for Training Deeper Graph Neural Networks: A Comprehensive Benchmark StudyT.Chen*, K. Zhou*, K. Duan, W. Zheng, P. Wang, X. Hu, and Z. Wang. [Paper] [Code] [Abstract] Experience Google, Research Intern [May 2022 - Aug. 2022] Mentor: Dr. Xianzhi Du, Dr. Denny Zhou IBM T. J. Watson Research Center, Part-time Research Intern [Oct. 2021 - Dec. 2021] Mentor: Dr. Horst Samulowitz, Dr. Lisa Amini Facebook Research, Research Intern [May. 2021 - Aug. 2021] Mentor: Dr. Xing Wang, Dr. Jason Chen Microsoft Research Redmond, Part-time Research Intern [Sep. 2020 - Dec. 2020] Mentor: Dr. Yu Cheng, Dr. Zhe Gan Microsoft Research Redmond, Research Intern [May. 2020 - Aug. 2020] Mentor: Dr. Yu Cheng, Dr. Zhe Gan, Dr. Yu Hu Walmart Technology, Research Intern [May. 2019 - Aug. 2019] Mentor: Dr. Yang Yang University of Science and Technology of China, Research Assistant [Jun. 2017 - Jun. 2018] Mentor: Dr. Zhouwang Yang Harvard University, Research Intern [Jul. 2016 - Jan. 2017] Mentor: Dr. Gil Alterovitz Research Award 2022 Adobe Ph.D. Fellowship Award, Jul. 2022 ICML 2022 Participation Grant, Jul. 2022 2021 Graduate Dean’s Prestigious Fellowship, Aug. 2021 2021 IBM Ph.D. Fellowship Award, Aug. 2021 3rd Place, ICCV 2019 WIDER Challenge Track 4, Oct. 2019 First Place, Walmart-TAMU Person Re-Identification (Re-ID) Competition, May. 2018 NeurIPS 2019 Student Travel Award, Dec. 2019 Media Coverage Shrinking massive neural networks used to model language, MIT News (Featured), Dec. 2020 Fooling deep neural networks for object detection with adversarial 3-D logos, Tech Xplore, Jul. 2020 More About Me I am a big fan of Pokemon. Playing Pokemon Go is one of my daily activities. I also enjoy Hip-Hop and Country music. Air (艾热) is one of my favorite Chinese Hip-Hop stars."},{"title":"Topics","date":"2018-08-01T05:00:00.000Z","updated":"2020-07-22T07:23:22.000Z","comments":true,"path":"tags/index.html","permalink":"https://tianlong-chen.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2018-08-01T05:00:00.000Z","updated":"2020-07-22T02:09:00.000Z","comments":true,"path":"categories/index.html","permalink":"https://tianlong-chen.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"(AAAI 2022) Playing Lottery Tickets with Vision and Language","slug":"AAAI-22","date":"2022-01-02T06:00:00.000Z","updated":"2021-12-06T04:58:12.000Z","comments":true,"path":"AAAI-22/","link":"","permalink":"https://tianlong-chen.github.io/AAAI-22/","excerpt":"","text":"Playing Lottery Tickets with Vision and Language[Paper] [Code] AbstractLarge-scale transformer-based pre-training has recently revolutionized vision-and-language (V+L) research. Models such as LXMERT, ViLBERT and UNITER have significantly lifted the state of the art over a wide range of V+L tasks. However, the large number of parameters in such models hinders their application in practice. In parallel, work on the lottery ticket hypothesis has shown that deep neural networks contain small matching subnetworks that can achieve on par or even better performance than the dense networks when trained in isolation. In this work, we perform the first empirical study to assess whether such trainable subnetworks also exist in pre-trained V+L models. We use UNITER, one of the best-performing V+L models, as the testbed, and consolidate 7 representative V+L tasks for experiments, including visual question answering, visual commonsense reasoning, visual entailment, referring expression comprehension, image-text retrieval, GQA, and NLVR . Through comprehensive analysis, we summarize our main findings as follows. (i) It is difficult to find subnetworks (i.e., the tickets) that strictly match the performance of the full UNITER model. However, it is encouraging to confirm that we can find “relaxed” winning tickets at 50%- 70% sparsity that maintain 99% of the full accuracy. (ii) Subnetworks found by task-specific pruning transfer reasonably well to the other tasks, while those found on the pre-training tasks at 60%/70% sparsity transfer universally, matching 98%/96% of the full accuracy on average over all the tasks. (iii) Adversarial training can be further used to enhance the performance of the found lottery tickets.","categories":[{"name":"AAAI'22","slug":"AAAI-22","permalink":"https://tianlong-chen.github.io/categories/AAAI-22/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"}]},{"title":"(WSDM 2022) Bringing Your Own View, Graph Contrastive Learning without Prefabricated Data Augmentations","slug":"WSDM22","date":"2022-01-01T06:00:00.000Z","updated":"2021-12-06T05:29:16.000Z","comments":true,"path":"WSDM22/","link":"","permalink":"https://tianlong-chen.github.io/WSDM22/","excerpt":"","text":"Bringing Your Own View: Graph Contrastive Learning without Prefabricated Data Augmentations[Paper] [Code] AbstractSelf supervision is recently surging at its new frontier of graph learning. It facilitates graph representations beneficial to downstream tasks; but its success could hinge on domain knowledge for handcraft or the often expensive trials and errors. Even its state-of-the-art representative, graph contrastive learning (GraphCL), is not completely free of those needs as GraphCL uses a prefabricated prior reflected by the ad-hoc manual selection of graph data augmentations. Our work aims at advancing GraphCL by answering the following questions: How to represent the space of graph augmented views? What principle can be relied upon to learn a prior in that space? And what framework can be constructed to learn the prior in tandem with contrastive learning? Accordingly we have extended the prefabricated discrete prior in the augmentation set, to a learnable continuous prior in the parameter space of graph generators, assuming that graph priors per se, similar to the concept of image manifolds, can be learned by data generation. Furthermore, to form contrastive views without collapsing to trivial solutions due to the prior learnability, we have leveraged both principles of information minimization (InfoMin) and information bottleneck (InfoBN) to regularize the learned priors. Eventually, contrastive learning, InfoMin, and InfoBN are incorporated organically into one framework of bi-level optimization. Our principled and automated approach has proven to be competitive against the state-of-the-art graph self-supervision methods, including GraphCL, on benchmarks of small graphs; and shown even better generalizability on large-scale graphs, without resorting to human expertise or downstream validation.","categories":[{"name":"WSDM'22","slug":"WSDM-22","permalink":"https://tianlong-chen.github.io/categories/WSDM-22/"}],"tags":[{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Contrasive Learning","slug":"Contrasive-Learning","permalink":"https://tianlong-chen.github.io/tags/Contrasive-Learning/"}]},{"title":"(ArXiv Preprint 2021) Learning to Optimize, A Primer and A Benchmark","slug":"Preprint-L2O","date":"2021-12-31T06:00:00.000Z","updated":"2021-03-26T21:42:43.000Z","comments":true,"path":"Preprint-L2O/","link":"","permalink":"https://tianlong-chen.github.io/Preprint-L2O/","excerpt":"","text":"Learning to Optimize: A Primer and A Benchmark[Paper] [Code] AbstractLearning to optimize (L2O) is an emerging approach that leverages machine learning to develop optimization methods, aiming at reducing the laborious iterations of hand engineering. It automates the design of an optimization method based on its performance on a set of training problems. This data-driven procedure generates methods that can efficiently solve problems similar to those in the training. In sharp contrast, the typical and traditional designs of optimization methods are theory-driven, so they obtain performance guarantees over the classes of problems specified by the theory. The difference makes L2O suitable for repeatedly solving a certain type of optimization problems over a specific distribution of data, while it typically fails on out-of-distribution problems. The practicality of L2O depends on the type of target optimization, the chosen architecture of the method to learn, and the training procedure. This new paradigm has motivated a community of researchers to explore L2O and report their findings. This article is poised to be the first comprehensive survey and benchmark of L2O for continuous optimization. We set up taxonomies, categorize existing works and research directions, present insights, and identify open challenges. We also benchmarked many existing L2O approaches on a few but representative optimization problems. For reproducible research and fair benchmarking purposes, we released our software implementation and data in the package Open-L2O at https://github.com/VITA-Group/Open-L2O.","categories":[{"name":"ArXiv Preprint","slug":"ArXiv-Preprint","permalink":"https://tianlong-chen.github.io/categories/ArXiv-Preprint/"}],"tags":[{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"}]},{"title":"(NeurIPS 2021) Chasing Sparsity in Vision Transformers, An End-to-End Exploration","slug":"NIPS21-ViT","date":"2021-12-06T06:00:00.000Z","updated":"2021-12-06T05:47:56.000Z","comments":true,"path":"NIPS21-ViT/","link":"","permalink":"https://tianlong-chen.github.io/NIPS21-ViT/","excerpt":"","text":"Chasing Sparsity in Vision Transformers: An End-to-End Exploration[Paper] [Code] AbstractVision transformers (ViTs) have recently received explosive popularity, but their enormous model sizes and training costs remain daunting. Conventional posttraining pruning often incurs higher training budgets. In contrast, this paper aims to trim down both the training memory overhead and the inference complexity, without sacrificing the achievable accuracy. We carry out the first-of-its-kind comprehensive exploration, on taking a unified approach of integrating sparsity in ViTs “from end to end”. Specifically, instead of training full ViTs, we dynamically extract and train sparse subnetworks, while sticking to a fixed small parameter budget. Our approach jointly optimizes model parameters and explores connectivity throughout training, ending up with one sparse network as the final output. The approach is seamlessly extended from unstructured to structured sparsity, the latter by considering to guide the prune-and-grow of self-attention heads inside ViTs. We further co-explore data and architecture sparsity for additional efficiency gains by plugging in a novel learnable token selector to adaptively determine the currently most vital patches. Extensive results on ImageNet with diverse ViT backbones validate the effectiveness of our proposals which obtain significantly reduced computational cost and almost unimpaired generalization. Perhaps most surprisingly, we find that the proposed sparse (co-)training can sometimes improve the ViT accuracy rather than compromising it, making sparsity a tantalizing “free lunch”. For example, our sparsified DeiT-Small at (5%, 50%) sparsity for (data, architecture), improves 0.28% top-1 accuracy, and meanwhile enjoys 49.32% FLOPs and 4.40% running time savings. Our codes are available at [https: //github.com/VITA-Group/SViTE](https: //github.com/VITA-Group/SViTE).","categories":[{"name":"NeurIPS'21","slug":"NeurIPS-21","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"Vision Transformer","slug":"Vision-Transformer","permalink":"https://tianlong-chen.github.io/tags/Vision-Transformer/"}]},{"title":"(NeurIPS 2021) Data-Efficient GAN Training Beyond (Just) Augmentation, A Lottery Ticket Perspective","slug":"NIPS21-DE","date":"2021-12-05T06:00:00.000Z","updated":"2021-12-06T05:30:55.000Z","comments":true,"path":"NIPS21-DE/","link":"","permalink":"https://tianlong-chen.github.io/NIPS21-DE/","excerpt":"","text":"Data-Efficient GAN Training Beyond (Just) Augmentation, A Lottery Ticket Perspective[Paper] [Code] AbstractTraining generative adversarial networks (GANs) with limited real image data generally results in deteriorated performance and collapsed models. To conquer this challenge, we are inspired by the latest observations, that one can discover independently trainable and highly sparse subnetworks (a.k.a., lottery tickets) from GANs. Treating this as an inductive prior, we suggest a brand-new angle towards data-efficient GAN training: by first identifying the lottery ticket from the original GAN using the small training set of real images; and then focusing on training that sparse subnetwork by re-using the same set. Both steps have lower complexity and are more data-efficient to train. We find our coordinated framework to offer orthogonal gains to existing real image data augmentation methods, and we additionally offer a new feature-level augmentation that can be applied together with them. Comprehensive experiments endorse the effectiveness of our proposed framework, across various GAN architectures (SNGAN, BigGAN, and StyleGAN-V2) and diverse datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet, and ImageNet). Our training framework also displays powerful few-shot generalization ability, i.e., generating high-fidelity images by training from scratch with just 100 real images, without any pre-training. Codes are available at: https://github.com/VITA-Group/Ultra-Data-Efficient-GAN-Training.","categories":[{"name":"NeurIPS'21","slug":"NeurIPS-21","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Adversarial Learning","slug":"Adversarial-Learning","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Learning/"},{"name":"Generative Adversarial Networks","slug":"Generative-Adversarial-Networks","permalink":"https://tianlong-chen.github.io/tags/Generative-Adversarial-Networks/"},{"name":"Data Efficiency","slug":"Data-Efficiency","permalink":"https://tianlong-chen.github.io/tags/Data-Efficiency/"}]},{"title":"(NeurIPS 2021) You are caught stealing my winning lottery ticket! Making a lottery ticket claim its ownership","slug":"NIPS21-PLTH","date":"2021-12-04T06:00:00.000Z","updated":"2021-12-06T06:00:00.000Z","comments":true,"path":"NIPS21-PLTH/","link":"","permalink":"https://tianlong-chen.github.io/NIPS21-PLTH/","excerpt":"","text":"You are caught stealing my winning lottery ticket! Making a lottery ticket claim its ownership[Paper] [Code] AbstractDespite tremendous success in many application scenarios, the training and inference costs of using deep learning are also rapidly increasing over time. The lottery ticket hypothesis (LTH) emerges as a promising framework to leverage a special sparse subnetwork (i.e., winning ticket) instead of a full model for both training and inference, that can lower both costs without sacrificing the performance. The main resource bottleneck of LTH is however the extraordinary cost to find the sparse mask of the winning ticket. That makes the found winning ticket become a valuable asset to the owners, highlighting the necessity of protecting its copyright. Our setting adds a new dimension to the recently soaring interest in protecting against the intellectual property (IP) infringement of deep models and verifying their ownerships, since they take owners’ massive/unique resources to develop or train. While existing methods explored encrypted weights or predictions, we investigate a unique way to leverage sparse topological information to perform lottery verification, by developing several graph-based signatures that can be embedded as credentials. By further combining trigger set-based methods, our proposal can work in both white-box and black-box verification scenarios. Through extensive experiments, we demonstrate the effectiveness of lottery verification in diverse models (ResNet-20, ResNet-18, ResNet-50) on CIFAR-10 and CIFAR-100. Specifically, our verification is shown to be robust to removal attacks such as model fine-tuning and pruning, as well as several ambiguity attacks. Our codes are available at https://github.com/VITA-Group/NO-stealing-LTH.","categories":[{"name":"NeurIPS'21","slug":"NeurIPS-21","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"Model Verification","slug":"Model-Verification","permalink":"https://tianlong-chen.github.io/tags/Model-Verification/"}]},{"title":"(NeurIPS 2021) Sparse Training via Boosting Pruning Plasticity with Neuroregeneration","slug":"NIPS21-GN","date":"2021-12-03T06:00:00.000Z","updated":"2021-12-06T06:02:25.000Z","comments":true,"path":"NIPS21-GN/","link":"","permalink":"https://tianlong-chen.github.io/NIPS21-GN/","excerpt":"","text":"Sparse Training via Boosting Pruning Plasticity with Neuroregeneration[Paper] [Code] AbstractWorks on lottery ticket hypothesis (LTH) and single-shot network pruning (SNIP) have raised a lot of attention currently on post-training pruning (iterative magnitude pruning), and before-training pruning (pruning at initialization). The former method suffers from an extremely large computation cost and the latter usually struggles with insufficient performance. In comparison, during-training pruning, a class of pruning methods that simultaneously enjoys the training/inference efficiency and the comparable performance, temporarily, has been less explored. To better understand during-training pruning, we quantitatively study the effect of pruning throughout training from the perspective of pruning plasticity (the ability of the pruned networks to recover the original performance). Pruning plasticity can help explain several other empirical observations about neural network pruning in literature. We further find that pruning plasticity can be substantially improved by injecting a brain-inspired mechanism called neuroregeneration, i.e., to regenerate the same number of connections as pruned. We design a novel gradual magnitude pruning (GMP) method, named gradual pruning with zerocost neuroregeneration (GraNet), that advances state of the art. Perhaps most impressively, its sparse-to-sparse version for the first time boosts the sparse-tosparse training performance over various dense-to-sparse methods with ResNet50 on ImageNet without extending the training time. We release all codes in https://github.com/Shiweiliuiiiiiii/GraNet.","categories":[{"name":"NeurIPS'21","slug":"NeurIPS-21","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"}]},{"title":"(NeurIPS 2021) Improving Contrastive Learning on Imbalanced Data via Open-World Sampling","slug":"NIPS21-CL","date":"2021-12-02T06:00:00.000Z","updated":"2021-12-06T06:21:59.000Z","comments":true,"path":"NIPS21-CL/","link":"","permalink":"https://tianlong-chen.github.io/NIPS21-CL/","excerpt":"","text":"Improving Contrastive Learning on Imbalanced Data via Open-World Sampling[Paper] [Code] AbstractContrastive learning approaches have achieved great success in learning visual representations with few labels of the target classes. That implies a tantalizing possibility of scaling them up beyond a curated “seed” benchmark, to incorporating more unlabeled images from the internet-scale external sources to enhance its performance. However, in practice, larger amount of unlabeled data will require more computing resources due to the bigger model size and longer training needed. Moreover, open-world unlabeled data usually follows an implicit long-tail class or attribute distribution, many of which also do not belong to the target classes. Blindly leveraging all unlabeled data hence can lead to the data imbalance as well as distraction issues. This motivates us to seek a principled approach to strategically select unlabeled data from an external source, in order to learn generalizable, balanced and diverse representations for relevant classes. In this work, we present an open-world unlabeled data sampling framework called Model-Aware K-center (MAK), which follows three simple principles: (1) tailness, which encourages sampling of examples from tail classes, by sorting the empirical contrastive loss expectation (ECLE) of samples over random data augmentations; (2) proximity, which rejects the out-of-distribution outliers that may distract training; and (3) diversity, which ensures diversity in the set of sampled examples. Empirically, using ImageNet-100-LT (without labels) as the seed dataset and two “noisy” external data sources, we demonstrate that MAK can consistently improve both the overall representation quality and the class balancedness of the learned features, as evaluated via linear classifier evaluation on full-shot and few-shot settings. The code is available at: https://github.com/VITA-Group/MAK.","categories":[{"name":"NeurIPS'21","slug":"NeurIPS-21","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Contrasive Learning","slug":"Contrasive-Learning","permalink":"https://tianlong-chen.github.io/tags/Contrasive-Learning/"},{"name":"Fairness","slug":"Fairness","permalink":"https://tianlong-chen.github.io/tags/Fairness/"}]},{"title":"(NeurIPS 2021) Sanity Checks for Lottery Tickets, Does Your Winning Ticket Really Win the Jackpot?","slug":"NIPS21-SLTH","date":"2021-12-01T06:00:00.000Z","updated":"2021-12-06T06:30:14.000Z","comments":true,"path":"NIPS21-SLTH/","link":"","permalink":"https://tianlong-chen.github.io/NIPS21-SLTH/","excerpt":"","text":"Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot?[Paper] [Code] AbstractThere have been long-standing controversies and inconsistencies over the experiment setup and criteria for identifying the “winning ticket” in literature. To reconcile such, we revisit the definition of lottery ticket hypothesis, with comprehensive and more rigorous conditions. Under our new definition, we show concrete evidence to clarify whether the winning ticket exists across the major DNN architectures and/or applications. Through extensive experiments, we perform quantitative analysis on the correlations between winning tickets and various experimental factors, and empirically study the patterns of our observations. We find that the key training hyperparameters, such as learning rate and training epochs, as well as the architecture characteristics such as capacities and residual connections, are all highly correlated with whether and when the winning tickets can be identified. Based on our analysis, we summarize a guideline for parameter settings in regards of specific architecture characteristics, which we hope to catalyze the research progress on the topic of lottery ticket hypothesis. Our codes are publicly available at: https://github.com/boone891214/sanity-check-LTH.","categories":[{"name":"NeurIPS'21","slug":"NeurIPS-21","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"}]},{"title":"(ICML 2021) A Unified Lottery Ticket Hypothesis for Graph Neural Networks","slug":"ICML21-GCNLTH","date":"2021-06-05T05:00:00.000Z","updated":"2021-06-06T01:13:46.000Z","comments":true,"path":"ICML21-GCNLTH/","link":"","permalink":"https://tianlong-chen.github.io/ICML21-GCNLTH/","excerpt":"","text":"A Unified Lottery Ticket Hypothesis for Graph Neural Networks[Paper] [Code] AbstractWith graphs rapidly growing in size and deeper graph neural networks (GNNs) emerging, the training and inference of GNNs become increasingly expensive. Existing network weight pruning algorithms cannot address the main space and computational bottleneck in GNNs, caused by the size and connectivity of the graph. To this end, this paper first presents a unified GNN sparsification (UGS) framework that simultaneously prunes the graph adjacency matrix and the model weights, for effectively accelerating GNN inference on large-scale graphs. Leveraging this new tool, we further generalize the recently popular lottery ticket hypothesis to GNNs for the first time, by defining a graph lottery ticket (GLT) as a pair of core sub-dataset and sparse sub-network, which can be jointly identified from the original GNN and the full dense graph by iteratively applying UGS. Like its counterpart in convolutional neural networks, GLT can be trained in isolation to match the performance of training with the full model and graph, and can be drawn from both randomly initialized and self-supervised pre-trained GNNs. Our proposal has been experimentally verified across various GNN architectures and diverse tasks, on both small-scale graph datasets (Cora, Citeseer and PubMed), and large-scale datasets from the challenging Open Graph Benchmark (OGB). Specifically, for node classification, our found GLTs achieve the same accuracies with 20%98% MACs saving on small graphs and 25%85% MACs saving on large ones. For link prediction, GLTs lead to 48%~97% and 70% MACs saving on small and large graph datasets, respectively, without compromising predictive performance.","categories":[{"name":"ICML'21","slug":"ICML-21","permalink":"https://tianlong-chen.github.io/categories/ICML-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"}]},{"title":"(ICML 2021) Efficient Lottery Ticket Finding, Less Data is More","slug":"ICML21-PAC","date":"2021-06-04T05:00:00.000Z","updated":"2021-06-06T01:39:42.000Z","comments":true,"path":"ICML21-PAC/","link":"","permalink":"https://tianlong-chen.github.io/ICML21-PAC/","excerpt":"","text":"Efficient Lottery Ticket Finding, Less Data is More[Paper] [Code] AbstractThe lottery ticket hypothesis (LTH) reveals the existence of winning tickets (sparse but critical subnetworks) for dense networks, that can be trained in isolation from random initialization to match the latter’s accuracies. However, finding winning tickets requires burdensome computations in the train-prune-retrain process, especially on large-scale datasets (e.g., ImageNet), restricting their practical benefits. This paper explores a new perspective on finding lottery tickets more efficiently, by doing so only with a specially selected subset of data, called Pruning-Aware Critical set (PrAC set), rather than using the full training set. The concept of PrAC set was inspired by the recent observation, that deep networks have samples that are either hard to memorize during training, or easy to forget during pruning. A PrAC set is thus hypothesized to capture those most challenging and informative examples for the dense model. We observe that a high-quality winning ticket can be found with training and pruning the dense network on the very compact PrAC set, which can substantially save training iterations for the ticket finding process. Extensive experiments validate our proposal across diverse datasets and network architectures. Specifically, on CIFAR-10, CIFAR-100, and Tiny ImageNet, we locate effective PrAC sets at 35.32%78.19%​ of their training set sizes. On top of them, we can obtain the same competitive winning tickets for the corresponding dense networks, yet saving up to 82.85%92.77%, 63.54%74.92%​, and 76.14%86.56% training iterations, respectively. Crucially, we show that a PrAC set found is reusable across different network architectures, which can amortize the extra cost of finding PrAC sets, yielding a practical regime for efficient lottery ticket finding.","categories":[{"name":"ICML'21","slug":"ICML-21","permalink":"https://tianlong-chen.github.io/categories/ICML-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"Data Efficiency","slug":"Data-Efficiency","permalink":"https://tianlong-chen.github.io/tags/Data-Efficiency/"}]},{"title":"(ICML 2021 Long Talk) Graph Contrastive Learning Automated","slug":"ICML21-JOAO","date":"2021-06-03T05:00:00.000Z","updated":"2021-06-08T22:23:49.000Z","comments":true,"path":"ICML21-JOAO/","link":"","permalink":"https://tianlong-chen.github.io/ICML21-JOAO/","excerpt":"","text":"Graph Contrastive Learning Automated[Paper] [Code] AbstractSelf-supervised learning on graph-structured data has drawn recent interest for learning generalizable, transferable and robust representations from unlabeled graphs. Among many, graph contrastive learning (GraphCL) has emerged with promising representation learning performance. Unfortunately, unlike its counterpart on image data, the effectiveness of GraphCL hinges on manually-picked ad-hoc data augmentations, which have to be manually picked per dataset, by either rules of thumb or trial-and-errors, owing to the diverse nature of graph data. That significantly limits the more general applicability of GraphCL. Aiming to fill in this crucial gap, this paper proposes a unified bi-level optimization framework to automatically, adaptively and dynamically select data augmentations when performing GraphCL on specific graph data. The general framework, dubbed JOint Augmentation Optimization (JOAO), is instantiated as min-max optimization. The selections of augmentations made by JOAO are shown to be in general aligned with previous “best practices” observed from manual tuning: yet now being fully automated, more flexible and versatile. Moreover, we propose a new augmentation-aware projection head mechanism, which will route output features through different projection heads corresponding to different augmentations chosen at each training step. Extensive experiments demonstrate that JOAO performs on par with or sometimes better than the state-of-the-art competitors including GraphCL, on multiple graph datasets of various scales and types, yet without resorting to any laborious dataset-specific tuning on augmentation selection. We release the code at https: //github.com/Shen-Lab/GraphCL_Automated.","categories":[{"name":"ICML'21","slug":"ICML-21","permalink":"https://tianlong-chen.github.io/categories/ICML-21/"}],"tags":[{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Contrasive Learning","slug":"Contrasive-Learning","permalink":"https://tianlong-chen.github.io/tags/Contrasive-Learning/"},{"name":"Graph Augmentation","slug":"Graph-Augmentation","permalink":"https://tianlong-chen.github.io/tags/Graph-Augmentation/"}]},{"title":"(ICML 2021 Long Talk) Sparse and Imperceptible Adversarial Attack via a Homotopy Algorithm","slug":"ICML21-HA","date":"2021-06-03T05:00:00.000Z","updated":"2021-06-06T01:48:19.000Z","comments":true,"path":"ICML21-HA/","link":"","permalink":"https://tianlong-chen.github.io/ICML21-HA/","excerpt":"","text":"Sparse and Imperceptible Adversarial Attack via a Homotopy Algorithm[Paper] [Code] AbstractSparse adversarial attacks can fool deep neural networks (DNNs) by only perturbing a few pixels (regularized by l_0 norm). Recent efforts combine it with another l_infty imperceptible on the perturbation magnitudes. The resultant sparse and imperceptible attacks are practically relevant, and indicate an even higher vulnerability of DNNs that we usually imagined. However, such attacks are more challenging to generate due to the optimization difficulty by coupling the l_0 regularizer and box constraints with a non-convex objective. In this paper, we address this challenge by proposing a homotopy algorithm, to jointly tackle the sparsity and the perturbation bound in one unified framework. Each iteration, the main step of our algorithm is to optimize an l_0-regularized adversarial loss, by leveraging the nonmonotone Accelerated Proximal Gradient Method (nmAPG) for nonconvex programming; it is followed by an l_0​ change control step, and an optional post-attack step designed to escape bad local minima. We also extend the algorithm to handling the structural sparsity regularizer. We extensively examine the effectiveness of our proposed homotopy attack for both targeted and non-targeted attack scenarios, on CIFAR-10 and ImageNet datasets. Compared to state-of-the-art methods, our homotopy attack leads to significantly fewer perturbations, e.g., reducing 43.94% on CIFAR-10 and 75.03% on ImageNet (average case, targeted attack), at similar maximal perturbation magnitudes, when still achieving 100% attack success rates.","categories":[{"name":"ICML'21","slug":"ICML-21","permalink":"https://tianlong-chen.github.io/categories/ICML-21/"}],"tags":[{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Adversarial Learning","slug":"Adversarial-Learning","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Learning/"}]},{"title":"(ICML 2021) Self-Damaging Contrasive Learning","slug":"ICML21-SDCL","date":"2021-06-02T05:00:00.000Z","updated":"2021-06-06T01:55:29.000Z","comments":true,"path":"ICML21-SDCL/","link":"","permalink":"https://tianlong-chen.github.io/ICML21-SDCL/","excerpt":"","text":"Self-Damaging Contrasive Learning[Paper] [Code] AbstractThe recent breakthrough achieved by contrastive learning accelerates the pace for deploying unsupervised training on real-world data applications. However, unlabeled data in reality is commonly imbalanced and shows a long-tail distribution, and it is unclear how robustly the latest contrastive learning methods could perform in the practical scenario. This paper proposes to explicitly tackle this challenge, via a principled framework called Self-Damaging Contrastive Learning (SDCLR), to automatically balance the representation learning without knowing the classes. Our main inspiration is drawn from the recent finding that deep models have difficult-to-memorize samples, and those may be exposed through network pruning. It is further natural to hypothesize that long-tail samples are also tougher for the model to learn well due to insufficient examples. Hence, the key innovation in SDCLR is to create a dynamic self-competitor model to contrast with the target model, which is a pruned version of the latter. During training, contrasting the two models will lead to adaptive online mining of the most easily forgotten samples for the current target model, and implicitly emphasize them more in the contrastive loss. Extensive experiments across multiple datasets and imbalance settings show that SDCLR significantly improves not only overall accuracies but also balancedness, in terms of linear evaluation on the full-shot and few-shot settings. Our code is available at https://github.com/VITA-Group/SDCLR.","categories":[{"name":"ICML'21","slug":"ICML-21","permalink":"https://tianlong-chen.github.io/categories/ICML-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Contrasive Learning","slug":"Contrasive-Learning","permalink":"https://tianlong-chen.github.io/tags/Contrasive-Learning/"},{"name":"Fairness","slug":"Fairness","permalink":"https://tianlong-chen.github.io/tags/Fairness/"}]},{"title":"(CVPR 2021) The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision Models","slug":"CVPR21-LTH","date":"2021-06-01T05:00:00.000Z","updated":"2021-06-06T02:23:33.000Z","comments":true,"path":"CVPR21-LTH/","link":"","permalink":"https://tianlong-chen.github.io/CVPR21-LTH/","excerpt":"","text":"The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision Models[Paper] [Code] AbstractThe computer vision world has been re-gaining enthusiasm in various pre-trained models, including both classical ImageNet supervised pre-training and recently emerged self-supervised pre-training such as simCLR and MoCo. Pre-trained weights often boost a wide range of downstream tasks including classification, detection, and segmentation. Latest studies suggest that the pre-training benefits from gigantic model capacity. We are hereby curious and ask: after pre-training, does a pre-trained model indeed have to stay large for its universal downstream transferability?In this paper, we examine the supervised and self-supervised pre-trained models through the lens of lottery ticket hypothesis (LTH). LTH identifies highly sparse matching subnetworks that can be trained in isolation from (nearly) scratch, to reach the full models’ performance. We extend the scope of LTH to questioning whether matching subnetworks still exist in the pre-training models, that enjoy the same downstream transfer performance. Our extensive experiments convey an overall positive message: from all pre-trained weights obtained by ImageNet classification, simCLR and MoCo, we are consistently able to locate such matching subnetworks at 59.04% to 96.48% sparsity that transfer universally to multiple downstream tasks, whose performance see no degradation compared to using full pre-trained weights. Further analyses reveal that subnetworks found from different pre-training tend to yield diverse mask structures and perturbation sensitivities. We conclude that the core LTH observations remain generally relevant in the pre-training paradigm of computer vision, but more delicate discussions are needed in some cases.","categories":[{"name":"CVPR'21","slug":"CVPR-21","permalink":"https://tianlong-chen.github.io/categories/CVPR-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"Detection","slug":"Detection","permalink":"https://tianlong-chen.github.io/tags/Detection/"},{"name":"Segmentation","slug":"Segmentation","permalink":"https://tianlong-chen.github.io/tags/Segmentation/"}]},{"title":"(CVPR 2021) Troubleshooting Blind Image Quality Models in the Wild","slug":"CVPR21-IQA","date":"2021-05-31T05:00:00.000Z","updated":"2021-06-06T02:23:27.000Z","comments":true,"path":"CVPR21-IQA/","link":"","permalink":"https://tianlong-chen.github.io/CVPR21-IQA/","excerpt":"","text":"Troubleshooting Blind Image Quality Models in the Wild[Paper] [Code] AbstractRecently, the group maximum differentiation competition (gMAD) has been used to troubleshoot blind image quality assessment (BIQA) models, with the help of multiple full-reference metrics. When applying this type of approach to troubleshoot “best-performing” BIQA models in the wild, we are faced with a practical challenge: it is highly nontrivial to obtain stronger competing models for efficient failure-spotting in gMAD. Inspired by recent findings that difficult samples of deep models may be exposed through network pruning, we construct a set of “self-competitors”, as random ensembles of pruned versions of the target model. Diverse failures can then be efficiently identified via self-competition in gMAD. Next, we fine-tune both the target and its pruned variants on the human-rated gMAD set. This allows all models to learn from their respective failures, and prepare themselves for the next round of the gMAD competition. Experimental results demonstrate that our method efficiently troubleshoots BIQA models in the wild with significantly improved generalizability.","categories":[{"name":"CVPR'21","slug":"CVPR-21","permalink":"https://tianlong-chen.github.io/categories/CVPR-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"Image Quality Assessment","slug":"Image-Quality-Assessment","permalink":"https://tianlong-chen.github.io/tags/Image-Quality-Assessment/"},{"name":"Model Comparison","slug":"Model-Comparison","permalink":"https://tianlong-chen.github.io/tags/Model-Comparison/"}]},{"title":"(CVPRW 2021 Spotlight Oral) BNN-BN=? Training Binary Neural Networks without Batch Normalization","slug":"CVPRW21","date":"2021-05-28T05:00:00.000Z","updated":"2021-12-06T06:29:49.000Z","comments":true,"path":"CVPRW21/","link":"","permalink":"https://tianlong-chen.github.io/CVPRW21/","excerpt":"","text":"BNN-BN=? Training Binary Neural Networks without Batch Normalization[Paper] [Code] AbstractBatch normalization (BN) is a key facilitator and considered essential for state-of-the-art binary neural networks (BNN). However, the BN layer is costly to calculate and is typically implemented with non-binary parameters, leaving a hurdle for the efficient implementation of BNN training. It also introduces undesirable dependence between samples within each batch. Inspired by the latest advance on Batch Normalization Free (BN-Free) training, we extend their framework to training BNNs, and for the first time demonstrate that BNs can be completed removed from BNN training and inference regimes. By plugging in and customizing techniques including adaptive gradient clipping, scale weight standardization, and specialized bottleneck block, a BN-free BNN is capable of maintaining competitive accuracy compared to its BN-based counterpart. Extensive experiments validate the effectiveness of our proposal across diverse BNN backbones and datasets. For example, after removing BNs from the state-of-the-art ReActNets, it can still be trained with our proposed methodology to achieve 92.08%, 68.34%, and 68.0% accuracy on CIFAR10, CIFAR-100, and ImageNet respectively, with marginal performance drop (0.23% ∼ 0.44% on CIFAR and 1.40% on ImageNet). Codes and pre-trained models are available at: https://github.com/VITA-Group/BNN_NoBN.","categories":[{"name":"CVPRW'21","slug":"CVPRW-21","permalink":"https://tianlong-chen.github.io/categories/CVPRW-21/"}],"tags":[{"name":"Binary Neural Network","slug":"Binary-Neural-Network","permalink":"https://tianlong-chen.github.io/tags/Binary-Neural-Network/"},{"name":"Normalization Free","slug":"Normalization-Free","permalink":"https://tianlong-chen.github.io/tags/Normalization-Free/"},{"name":"Batch Normalization","slug":"Batch-Normalization","permalink":"https://tianlong-chen.github.io/tags/Batch-Normalization/"}]},{"title":"(ICLR 2021) Robust Overfitting may be mitigated by properly learned smoothening","slug":"ICLR21-ADV","date":"2021-05-02T05:00:00.000Z","updated":"2021-03-04T16:52:30.000Z","comments":true,"path":"ICLR21-ADV/","link":"","permalink":"https://tianlong-chen.github.io/ICLR21-ADV/","excerpt":"","text":"Robust Overfitting may be mitigated by properly learned smoothening[Paper] [Code] AbstractA recent study (Rice et al., 2020) revealed overfitting to be a dominant phenomenon in adversarially robust training of deep networks, and that appropriate early-stopping of adversarial training (AT) could match the performance gains of most recent algorithmic improvements. This intriguing problem of robust overfitting motivates us to seek more remedies. As a pilot study, this paper investigates two empirical means to inject more learned smoothening during AT: one leveraging knowledge distillation and self-training to smooth the logits, the other performing stochastic weight averaging (Izmailov et al., 2018) to smooth the weights. Despite the embarrassing simplicity, the two approaches are surprisingly effective and hassle-free in mitigating robust overfitting. Experiments demonstrate that by plugging in them to AT, we can simultaneously boost the standard accuracy by 3.72%~6.68% and robust accuracy by 0.22%~2 .03%, across multiple datasets (STL-10, SVHN, CIFAR-10, CIFAR-100, and Tiny ImageNet), perturbation types (ℓ∞ and ℓ2), and robustified methods (PGD, TRADES, and FSGM), establishing the new state-of-the-art bar in AT. We present systematic visualizations and analysis to dive into their possible working mechanisms. We also carefully exclude the possibility of gradient masking by evaluating our models’ robustness against transfer attacks.","categories":[{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"}],"tags":[{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Knowledge Distillation","slug":"Knowledge-Distillation","permalink":"https://tianlong-chen.github.io/tags/Knowledge-Distillation/"}]},{"title":"(ICLR 2021) Long Live the Lottery, The Existence of Winning Tickets in Lifelong Learning","slug":"ICLR21-LifeLT","date":"2021-05-01T05:00:00.000Z","updated":"2021-02-08T02:18:35.000Z","comments":true,"path":"ICLR21-LifeLT/","link":"","permalink":"https://tianlong-chen.github.io/ICLR21-LifeLT/","excerpt":"","text":"Long Live the Lottery: The Existence of Winning Tickets in Lifelong Learning[Paper] [Code] AbstractThe lottery ticket hypothesis demonstrates that a highly sparsified sub-network can be trained in isolation, given the appropriate weight initialization. This paper extends that hypothesis from one-shot task leaning, and demonstrate for the first time that such extremely compact and independently trainable sub-networks can be also identified in the lifelong learning scenario, which we call lifelong tickets. We show that the resulting lifelong ticket can further be leveraged to improve the performance of learning over continual tasks. However, it is highly non-trivial to conduct network pruning in the lifelong setting. Two critical roadblocks arise: i) As many tasks now arrive sequentially, finding tickets in a greedy weight pruning fashion will inevitably suffer from the intrinsic bias, that the earlier emerging tasks impact more; ii) As lifelong learning is consistently challenged by catastrophic forgetting, the compact network capacity of tickets might amplify the risk of forgetting. In view of those, we introduce two pruning options, e.g., top-down and bottom-up, for finding lifelong tickets. Compared to the top-down pruning that extends vanilla (iterative) pruning over sequential tasks, we show that the bottom-up one, which can dynamically shrink and (re-)expand model capacity, effectively avoids the undesirable excessive pruning in the early stage. We additionally introduce lottery teaching that further overcomes forgetting via knowledge distillation aided by external unlabeled data. Unifying those ingredients, we demonstrate the existence of very competitive lifelong tickets, e.g., achieving 3-8% of the dense model size with even higher accuracy, compared to strong class-incremental learning baselines on CIFAR-10/CIFAR-100/Tiny-ImageNet datasets.","categories":[{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Lifelong Learning","slug":"Lifelong-Learning","permalink":"https://tianlong-chen.github.io/tags/Lifelong-Learning/"}]},{"title":"(ICLR 2021) GANs Can Play Lottery Tickets Too","slug":"ICLR21-GAN","date":"2021-04-30T05:00:00.000Z","updated":"2021-02-08T02:18:33.000Z","comments":true,"path":"ICLR21-GAN/","link":"","permalink":"https://tianlong-chen.github.io/ICLR21-GAN/","excerpt":"","text":"GANs Can Play Lottery Tickets Too[Paper] [Code] AbstractDeep generative adversarial networks (GANs) have gained growing popularity in numerous scenarios, while usually suffer from high parameter complexities for resource-constrained real-world applications. However, the compression of GANs has less been explored. A few works show that heuristically applying compression techniques normally leads to unsatisfactory results, due to the notorious training instability (of GANs). In parallel, the lottery ticket hypothesis shows prevailing success on discriminative models, in locating sparse matching subnetworks capable of training in isolation to full model performance. In this work, we for the first time study the existence of such trainable matching subnetworks in deep GANs. For a range of GANs, we certainly find matching subnetworks at 67%-74% sparsity. We observe that with or without pruning discriminator has a minor effect on the existence and quality of matching subnetworks, while the initialization used in the discriminator plays a significant role. We then show the powerful transferability of these subnetworks to unseen tasks. Furthermore, extensive experimental results demonstrate that our found subnetworks substantially outperform previous state-of-the-art GAN compression approaches in both image generation (e.g. SNGAN) and image-to-image translation GANs (e.g. CycleGAN).","categories":[{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Adversarial Learning","slug":"Adversarial-Learning","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Learning/"},{"name":"Generative Adversarial Networks","slug":"Generative-Adversarial-Networks","permalink":"https://tianlong-chen.github.io/tags/Generative-Adversarial-Networks/"}]},{"title":"(ICLR 2021 Spotlight Oral) Undistillable, Making A Nasty Teacher That CANNOT teach students","slug":"ICLR21-NastyT","date":"2021-04-29T05:00:00.000Z","updated":"2021-02-08T01:57:29.000Z","comments":true,"path":"ICLR21-NastyT/","link":"","permalink":"https://tianlong-chen.github.io/ICLR21-NastyT/","excerpt":"","text":"Undistillable: Making A Nasty Teacher That CANNOT teach students[Paper] [Code] AbstractKnowledge Distillation (KD) is a widely used technique to transfer knowledge from pre-trained teacher models to (usually more lightweight) student models. However, in certain situations, this technique is more of a curse than a blessing. For instance, KD poses a potential risk of exposing intellectual properties (IPs): even if a trained machine learning model is released in ``black boxes’’ (e.g., as executable software or APIs without open-sourcing code), it can still be replicated by KD through imitating input-output behaviors. To prevent this unwanted effect of KD, this paper introduces and investigates a concept called Nasty Teacher: a specially trained teacher network that yields nearly the same performance as a normal one, but would significantly degrade the performance of student models learned by imitating it. We propose a simple yet effective algorithm to build the nasty teacher, called self-undermining knowledge distillation. Specifically, we aim to maximize the difference between the output of the nasty teacher and a normal pre-trained network. Extensive experiments on several datasets demonstrate that our method is effective on both standard KD and data-free KD, providing the desirable KD-immunity to model owners for the first time. We hope our preliminary study can draw more awareness and interest in this new practical problem of both social and legal importance.","categories":[{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"}],"tags":[{"name":"Adversarial Learning","slug":"Adversarial-Learning","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Learning/"},{"name":"Knowledge Distillation","slug":"Knowledge-Distillation","permalink":"https://tianlong-chen.github.io/tags/Knowledge-Distillation/"},{"name":"Privacy Preserving","slug":"Privacy-Preserving","permalink":"https://tianlong-chen.github.io/tags/Privacy-Preserving/"}]},{"title":"(ICLR 2021) Learning A Minimax Optimizer, A Pilot Study","slug":"ICLR21-L2O","date":"2021-04-28T05:00:00.000Z","updated":"2021-02-08T02:03:32.000Z","comments":true,"path":"ICLR21-L2O/","link":"","permalink":"https://tianlong-chen.github.io/ICLR21-L2O/","excerpt":"","text":"Learning A Minimax Optimizer: A Pilot Study[Paper] [Code] AbstractSolving continuous minimax optimization is of extensive practical interest, yet notoriously unstable and difficult. This paper introduces the learning to optimize (L2O) methodology to the minimax problems for the first time, and addresses its accompanying unique challenges. We first present Twin L2O, the first dedicated minimax L2O framework consisting of two LSTMs for updating min and max variables, respectively. That decoupled design is found to facilitate learning, particularly when the min and max variables are highly non-symmetric. Empirical experiments on a variety of minimax problems corroborates the effectiveness of Twin-L2O. We then discuss a crucial concern of Twin-L2O, i.e., its inevitably limited generalizability to unseen optimizees, and present two complementary strategies. Our first solution, Enhanced Twin-L2O, is empirically applicable for general minimax problems, by improving L2O training via leveraging curriculum learning. We extensively benchmark our algorithms on popular minimax problems, and compare against state-of-the-art minimax solvers. Our second alternative, called Safeguarded Twin L2O, is a preliminary theoretical exploration stating that under some strong assumptions, it is possible to theoretically establish the convergence of Twin-L2O on optimizing any unseen objective.","categories":[{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"}],"tags":[{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Curriculum Learning","slug":"Curriculum-Learning","permalink":"https://tianlong-chen.github.io/tags/Curriculum-Learning/"}]},{"title":"(ArXiv Preprint 2021) Adversarial Feature Augmentation and Normalization for Visual Recognition","slug":"Preprint-AFAN","date":"2021-03-17T05:00:00.000Z","updated":"2021-03-26T21:39:03.000Z","comments":true,"path":"Preprint-AFAN/","link":"","permalink":"https://tianlong-chen.github.io/Preprint-AFAN/","excerpt":"","text":"Adversarial Feature Augmentation and Normalization for Visual Recognition[Paper] [Code] AbstractRecent advances in computer vision take advantage of adversarial data augmentation to ameliorate the generalization ability of classification models. Here, we present an effective and efficient alternative that advocates adversarial augmentation on intermediate feature embeddings, instead of relying on computationally-expensive pixel-level perturbations. We propose Adversarial Feature Augmentation and Normalization (A-FAN), which (i​) first augments visual recognition models with adversarial features that integrate flexible scales of perturbation strengths, (ii​) then extracts adversarial feature statistics from batch normalization, and re-injects them into clean features through feature normalization. We validate the proposed approach across diverse visual recognition tasks with representative backbone networks, including ResNets and EfficientNets for classification, Faster-RCNN for detection, and Deeplab V3+ for segmentation. Extensive experiments show that A-FAN yields consistent generalization improvement over strong baselines across various datasets for classification, detection and segmentation tasks, such as CIFAR-10, CIFAR-100, ImageNet, Pascal VOC2007, Pascal VOC2012, COCO2017, and Cityspaces. Comprehensive ablation studies and detailed analyses also demonstrate that adding perturbations to specific modules and layers of classification/detection/segmentation backbones yields optimal performance. Codes and pre-trained models will be made available at: https://github.com/VITA-Group/CV_A-FAN.","categories":[{"name":"ArXiv Preprint","slug":"ArXiv-Preprint","permalink":"https://tianlong-chen.github.io/categories/ArXiv-Preprint/"}],"tags":[{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Detection","slug":"Detection","permalink":"https://tianlong-chen.github.io/tags/Detection/"},{"name":"Segmentation","slug":"Segmentation","permalink":"https://tianlong-chen.github.io/tags/Segmentation/"}]},{"title":"(ICASSP 2021) VGAI, End-to-End Learning of Vision-Based Decentralized Controllers for Robot Swarms","slug":"ICASSP21","date":"2021-03-01T06:00:00.000Z","updated":"2021-06-06T01:45:23.000Z","comments":true,"path":"ICASSP21/","link":"","permalink":"https://tianlong-chen.github.io/ICASSP21/","excerpt":"","text":"VGAI: End-to-End Learning of Vision-Based Decentralized Controllers for Robot Swarms[Paper] [Code] AbstractDecentralized coordination of a robot swarm requires addressing the tension between local perceptions and actions, and the accomplishment of a global objective. In this work, we propose to learn decentralized controllers based on solely raw visual inputs. For the first time, that integrates the learning of two key components: communication and visual perception, in one end-to-end framework. More specifically, we consider that each robot has access to a visual perception of the immediate surroundings, and communication capabilities to transmit and receive messages from other neighboring robots. Our proposed learning framework combines a convolutional neural network (CNN) for each robot to extract messages from the visual inputs, and a graph neural network (GNN) over the entire swarm to transmit, receive and process these messages in order to decide on actions. The use of a GNN and locally-run CNNs results naturally in a decentralized controller. We jointly train the CNNs and the GNN so that each robot learns to extract messages from the images that are adequate for the team as a whole. Our experiments demonstrate the proposed architecture in the problem of drone flocking and show its promising performance and scalability, e.g., achieving successful decentralized flocking for large-sized swarms consisting of up to 75 drones.","categories":[{"name":"ICASSP'21","slug":"ICASSP-21","permalink":"https://tianlong-chen.github.io/categories/ICASSP-21/"}],"tags":[{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Imitation Learning","slug":"Imitation-Learning","permalink":"https://tianlong-chen.github.io/tags/Imitation-Learning/"}]},{"title":"(AAAIW 2021 Oral) AR-Stock, Deep Augmented Relational Stock Prediction","slug":"AAAIW-21","date":"2021-01-07T06:00:00.000Z","updated":"2021-12-06T04:47:46.000Z","comments":true,"path":"AAAIW-21/","link":"","permalink":"https://tianlong-chen.github.io/AAAIW-21/","excerpt":"","text":"AR-Stock: Deep Augmented Relational Stock Prediction[Paper] [Code] AbstractStock prediction aims to assess future price trends and assist investment decisions. With the recent success of graph convolutional networks (GCNs) in modeling relational data, they have also shown promise for stock prediction. However, vanilla GCNs lack the ability to capture long-range dependencies in graphs and have not fully utilized the structured knowledge with data available. In this paper, we propose a novel framework of Deep Augmented Relational Stock Prediction (AR-Stock). We first detect the long-range links using pre-trained knowledge graph embeddings, leading to a new geometrically augmented edge type into the provided stock market graph. We then construct the GCN model on this augmented graph, that predicts each company’s stock prices by leveraging its related corporations; specifically, to train the GCNs better over this complex graph, we introduce two novel self-supervised regularizers (graph partition and graph completion) to inform the model with the global and local topology features. Unifying the above ingredients, AR-Stock has the unique strength in capturing long-term and hidden graph node dependencies. Experiments on two popular stock market datasets, NASDAQ and NYSE, demonstrate the prediction superiority of AR-Stock. Particularly, in terms of the investment return ratio, AR-Stock improves 65.77% in NASDAQ, and 30.48% in NYSE, over state-of-the-art models, respectively.","categories":[{"name":"AAAIW'21","slug":"AAAIW-21","permalink":"https://tianlong-chen.github.io/categories/AAAIW-21/"}],"tags":[{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"}]},{"title":"(ArXiv Preprint 2021) Good Students Play Big Lottery Better","slug":"Preprint-KDLTH","date":"2021-01-05T06:00:00.000Z","updated":"2021-02-08T03:37:47.000Z","comments":true,"path":"Preprint-KDLTH/","link":"","permalink":"https://tianlong-chen.github.io/Preprint-KDLTH/","excerpt":"","text":"Good Students Play Big Lottery Better[Paper] [Code] AbstractLottery ticket hypothesis suggests that a dense neural network contains a sparse sub-network that can match the test accuracy of the original dense net when trained in isolation from (the same) random initialization. However, the hypothesis failed to generalize to larger dense networks such as ResNet-50. As a remedy, recent studies demonstrate that a sparse sub-network can still be obtained by using a rewinding technique, which is to re-train it from early-phase training weights or learning rates of the dense model, rather than from random initialization.Is rewinding the only or the best way to scale up lottery tickets? This paper proposes a new, simpler and yet powerful technique for re-training the sub-network, called “Knowledge Distillation ticket” (KD ticket). Rewinding exploits the value of inheriting knowledge from the early training phase to improve lottery tickets in large networks. In comparison, KD ticket addresses a complementary possibility - inheriting useful knowledge from the late training phase of the dense model. It is achieved by leveraging the soft labels generated by the trained dense model to re-train the sub-network, instead of the hard labels. Extensive experiments are conducted using several large deep networks (e.g ResNet-50 and ResNet-110) on CIFAR-10 and ImageNet datasets. Without bells and whistles, when applied by itself, KD ticket performs on par or better than rewinding, while being nearly free of hyperparameters or ad-hoc selection. KD ticket can be further applied together with rewinding, yielding state-of-the-art results for large-scale lottery tickets.","categories":[{"name":"ArXiv Preprint","slug":"ArXiv-Preprint","permalink":"https://tianlong-chen.github.io/categories/ArXiv-Preprint/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Knowledge Distillation","slug":"Knowledge-Distillation","permalink":"https://tianlong-chen.github.io/tags/Knowledge-Distillation/"}]},{"title":"(NeurIPS 2020 Spotlight Oral) Training Stronger Baselines for Learning to Optimize","slug":"NIPS20-L2O","date":"2020-12-06T06:00:00.000Z","updated":"2021-02-01T21:38:53.000Z","comments":true,"path":"NIPS20-L2O/","link":"","permalink":"https://tianlong-chen.github.io/NIPS20-L2O/","excerpt":"","text":"Training Stronger Baselines for Learning to Optimize[Paper] [Code] AbstractLearning to optimize (L2O) has gained increasing attention since classical optimizers require laborious problem-specific design and hyperparameter tuning. However, there is a gap between the practical demand and the achievable performance of existing L2O models. Specifically, those learned optimizers are applicable to only a limited class of problems, and often exhibit instability. With many efforts devoted to designing more sophisticated L2O models, we argue for another orthogonal, under-explored theme: the training techniques for those L2O models. We show that even the simplest L2O model could have been trained much better. We first present a progressive training scheme to gradually increase the optimizer unroll length, to mitigate a well-known L2O dilemma of truncation bias (shorter unrolling) versus gradient explosion (longer unrolling). We further leverage off-policy imitation learning to guide the L2O learning , by taking reference to the behavior of analytical optimizers. Our improved training techniques are plugged into a variety of state-of-the-art L2O models, and immediately boost their performance, without making any change to their model structures. Especially, by our proposed techniques, an earliest and simplest L2O model can be trained to outperform the latest complicated L2O models on a number of tasks. Our results demonstrate a greater potential of L2O yet to be unleashed, and urge to rethink the recent progress. The codes are publicly available at: https://github.com/VITA-Group/L2O-Training-Techniques.","categories":[{"name":"NeurIPS'20","slug":"NeurIPS-20","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-20/"}],"tags":[{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Imitation Learning","slug":"Imitation-Learning","permalink":"https://tianlong-chen.github.io/tags/Imitation-Learning/"},{"name":"Curriculum Learning","slug":"Curriculum-Learning","permalink":"https://tianlong-chen.github.io/tags/Curriculum-Learning/"}]},{"title":"(NeurIPS 2020) The Lottery Ticket Hypothesis for Pre-trained BERT Networks","slug":"NIPS20-BERT","date":"2020-12-05T06:00:00.000Z","updated":"2020-09-26T04:04:41.000Z","comments":true,"path":"NIPS20-BERT/","link":"","permalink":"https://tianlong-chen.github.io/NIPS20-BERT/","excerpt":"","text":"The Lottery Ticket Hypothesis for Pre-trained BERT Networks[Paper] [Code] AbstractIn natural language processing (NLP), enormous pre-trained models like BERT have become the standard starting point for training on a range of downstream tasks, and similar trends are emerging in other areas of deep learning. In parallel, work on the lottery ticket hypothesis has shown that models for NLP and computer vision contain smaller matching subnetworks capable of training in isolation to full accuracy and transferring to other tasks. In this work, we combine these observations to assess whether such trainable, transferrable subnetworks exist in pre-trained BERT models. For a range of downstream tasks, we indeed find matching subnetworks at 40% to 90% sparsity. We find these subnetworks at (pre-trained) initialization, a deviation from prior NLP research where they emerge only after some amount of training. Subnetworks found on the masked language modeling task (the same task used to pre-train the model) transfer universally; those found on other tasks transfer in a limited fashion if at all. As large-scale pre-training becomes an increasingly central paradigm in deep learning, our results demonstrate that the main lottery ticket observations remain relevant in this context. Codes available at https://github.com/VITA-Group/BERT-Tickets.","categories":[{"name":"NeurIPS'20","slug":"NeurIPS-20","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-20/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://tianlong-chen.github.io/tags/Natural-Language-Processing/"},{"name":"BERT","slug":"BERT","permalink":"https://tianlong-chen.github.io/tags/BERT/"}]},{"title":"(NeurIPS 2020) Once-for-All Adversarial Training, In-Situ Trade off between Robustness and Accuracy for Free","slug":"NIPS20-CAT","date":"2020-12-04T06:00:00.000Z","updated":"2021-02-01T21:40:05.000Z","comments":true,"path":"NIPS20-CAT/","link":"","permalink":"https://tianlong-chen.github.io/NIPS20-CAT/","excerpt":"","text":"Once-for-All Adversarial Training: In-Situ Trade off between Robustness and Accuracy for Free[Paper] [Code] AbstractAdversarial training and its many variants substantially improve deep network robustness, yet at the cost of compromising standard accuracy. Moreover, the training process is heavy and hence it becomes impractical to thoroughly explore the trade-off between accuracy and robustness. This paper asks this new question: how to quickly calibrate a trained model in-situ, to examine the achievable trade-offs between its standard and robust accuracies, without (re-)training it many times? Our proposed framework, Calibratable Adversarial Training (CAT), is built on an innovative model-conditional training framework, with a controlling hyper-parameter as the input. The resulting model could be adjusted among different standard and robust accuracies “for free” at testing time. As an important knob, we exploit dual batch normalization to separate standard and adversarial feature statistics, so that they can be learned in one model without degrading performance. We further extend CAT to a Calibratable Adversarial Training and Slimming (CATS) framework, that allows for the joint trade-off among accuracy, robustness and runtime efficiency. Experiments show that, without any re-training nor ensembling, CAT/CATS achieve similar or even superior performance compared to dedicatedly trained models at various configurations. All codes and pretrained models will be released upon acceptance. The codes are publicly available at: https://github.com/VITA-Group/Once-for-All-Adversarial-Training.","categories":[{"name":"NeurIPS'20","slug":"NeurIPS-20","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-20/"}],"tags":[{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"Batch Normalization","slug":"Batch-Normalization","permalink":"https://tianlong-chen.github.io/tags/Batch-Normalization/"}]},{"title":"(NeurIPS 2020) Pre-Training Graph Neural Networks A Contrastive Learning Framework with Augmentations","slug":"NIPS20-GCNCL","date":"2020-12-03T06:00:00.000Z","updated":"2021-02-01T21:41:15.000Z","comments":true,"path":"NIPS20-GCNCL/","link":"","permalink":"https://tianlong-chen.github.io/NIPS20-GCNCL/","excerpt":"","text":"Pre-Training Graph Neural Networks: A Contrastive Learning Framework with Augmentations[Paper] [Code] AbstractGeneralizable, transferrable, and robust representation learning on graph-structured data remains a challenge for current graph neural networks (GNNs). Unlike what has been developed for convolutional neural networks (CNNs) for image data, self-supervised learning and pre-training are intrinsically difficult to pursue and indeed rarely explored for GNNs. In this paper, we propose a graph contrastive learning (GraphCL) framework to learn perturbation-invariant unsupervised representations of graph data. To this end, we first design four types of graph augmentations to incorporate various priors. Furthermore, we systematically assess, summarize, and rationalize the impact of contrasting various combinations of graph augmentations on various datasets, in the setting of semi-supervised, unsupervised, and transfer learning as well as adversarial attacks. The results show that, even without tuning augmentation extents nor using sophisticated GNN architectures, our GraphCL framework can produce graph representations of similar or better generalizability, transferrability, and robustness compared to state-of-the-art methods. We also investigate the impact of parameterized graph augmentation extents and patterns, and observe further performance gains in preliminary experiments. The codes are publicly available at:.","categories":[{"name":"NeurIPS'20","slug":"NeurIPS-20","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-20/"}],"tags":[{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Contrasive Learning","slug":"Contrasive-Learning","permalink":"https://tianlong-chen.github.io/tags/Contrasive-Learning/"},{"name":"Graph Augmentation","slug":"Graph-Augmentation","permalink":"https://tianlong-chen.github.io/tags/Graph-Augmentation/"}]},{"title":"(NeurIPS 2020) Adversarial Contrastive Learning, Harvesting More Robustness from Unsupervised Pre-Training","slug":"NIPS20-ADVCL","date":"2020-12-02T06:00:00.000Z","updated":"2021-02-08T01:02:58.000Z","comments":true,"path":"NIPS20-ADVCL/","link":"","permalink":"https://tianlong-chen.github.io/NIPS20-ADVCL/","excerpt":"","text":"Adversarial Contrastive Learning: Harvesting More Robustness from Unsupervised Pre-Training[Paper] [Code] AbstractRecent work has shown that, when integrated with adversarial training, self-supervised pre-training with several pretext tasks can lead to state-of-the-art robustness. In this work, we show that contrasting features to random and adversarial perturbations for consistency can benefit robustness-aware pre-training even further. Our approach leverages a recent contrastive learning framework, which learns representations by maximizing feature consistency under differently augmented views. This fits particularly well with the goal of adversarial robustness, as one cause of adversarial fragility is the lack of feature invariance, i.e., small input perturbations can result in undesirable large changes in features or even predicted labels. We explore various options to formulate the contrastive task, and demonstrate that by injecting adversarial augmentations, contrastive pre-training indeed contributes to learning data-efficient robust models. We extensively evaluate the proposed Adversarial Contrastive Learning (ACL) and show it can consistently outperform state-of-the-arts. For example on the CIFAR-10 dataset, ACL outperforms the latest unsupervised robust pre-training approach with substantial margins: 2.99% on robust accuracy and 2.14% on standard accuracy. We further demonstrate that ACL pre-training can improve semi-supervised adversarial training, even at very low label rates. The codes are publicly available at:.","categories":[{"name":"NeurIPS'20","slug":"NeurIPS-20","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-20/"}],"tags":[{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Contrasive Learning","slug":"Contrasive-Learning","permalink":"https://tianlong-chen.github.io/tags/Contrasive-Learning/"}]},{"title":"(InterSpeech 2020) AutoSpeech, Neural Architecture Search for Speaker Recognition","slug":"InterSpeech20","date":"2020-10-26T05:00:00.000Z","updated":"2020-09-26T23:42:56.000Z","comments":true,"path":"InterSpeech20/","link":"","permalink":"https://tianlong-chen.github.io/InterSpeech20/","excerpt":"","text":"AutoSpeech: Neural Architecture Search for Speaker Recognition[Paper] [Code] AbstractSpeaker recognition systems based on Convolutional Neural Networks (CNNs) are often built with off-the-shelf backbones such as VGG-Net or ResNet. However, these backbones were originally proposed for image classification, and therefore may not be naturally fit for speaker recognition. Due to the prohibitive complexity of manually exploring the design space, we propose the first neural architecture search approach approach for the speaker recognition tasks, named as AutoSpeech. Our algorithm first identifies the optimal operation combination in a neural cell and then derives a CNN model by stacking the neural cell for multiple times. The final speaker recognition model can be obtained by training the derived CNN model through the standard scheme. To evaluate the proposed approach, we conduct experiments on both speaker identification and speaker verification tasks using the VoxCeleb1 dataset. Results demonstrate that the derived CNN architectures from the proposed approach significantly outperform current speaker recognition systems based on VGG-M, ResNet-18, and ResNet-34 backbones, while enjoying lower model complexity.","categories":[{"name":"InterSpeech'20","slug":"InterSpeech-20","permalink":"https://tianlong-chen.github.io/categories/InterSpeech-20/"}],"tags":[{"name":"Speaker Recognition","slug":"Speaker-Recognition","permalink":"https://tianlong-chen.github.io/tags/Speaker-Recognition/"},{"name":"Neural Archtecture Search","slug":"Neural-Archtecture-Search","permalink":"https://tianlong-chen.github.io/tags/Neural-Archtecture-Search/"}]},{"title":"(ECCV 2020) HALO, Hardware-Aware Learning to Optimize","slug":"ECCV20-HALO","date":"2020-08-23T05:00:00.000Z","updated":"2020-09-26T23:42:00.000Z","comments":true,"path":"ECCV20-HALO/","link":"","permalink":"https://tianlong-chen.github.io/ECCV20-HALO/","excerpt":"","text":"HALO: Hardware-Aware Learning to Optimize[Paper] [Code] AbstractThere has been an explosive demand for bringing machine learning (ML) powered intelligence into numerous Internet-of-Things (IoT) devices. However, the effectiveness of such intelligent functionality requires in-situ continuous model adaptation for adapting to new dataand environments, while the on-device computing and energy resources are usually extremely constrained. Neither traditional hand-crafted (e.g., SGD, Adagrad, and Adam) nor existing meta optimizers are specifically designed to meet those challenges, as the former requires tedious hyper-parameter tuning while the latter are often costly due to themeta algorithms’ own overhead. To this end, we propose hardware-aware learning to optimize (HALO), a practical meta optimizer dedicated to resource-efficient on-device adaptation. Our HALO optimizer features the following highlights: (1) faster adaptation speed (i.e., taking fewer data oriterations to reach a specified accuracy) by introducing a new regularizer to promote empirical generalization; and (2) lower per-iteration complexity, thanks to a stochastic structural sparsity regularizer being enforced. Furthermore, the optimizer itself is designed as a very light-weight RNN and thus incurs negligible overhead. Ablation studies and experiments onfive datasets, six optimizees, and two state-of-the-art (SOTA) edge AIdevices validate that, while always achieving a better accuracy (↑0.46% -↑20.28%), HALO can greatly trim down the energy cost (up to↓60%) inadaptation, quantified using an IoT device or SOTA simulator. Codesand pre-trained models are at https://github.com/RICE-EIC/HALO .","categories":[{"name":"ECCV'20","slug":"ECCV-20","permalink":"https://tianlong-chen.github.io/categories/ECCV-20/"}],"tags":[{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"Adaptation","slug":"Adaptation","permalink":"https://tianlong-chen.github.io/tags/Adaptation/"}]},{"title":"(ICML 2020) When Does Self-Supervision Help Graph Convolutional Networks?","slug":"ICML20-GCN","date":"2020-07-12T05:00:00.000Z","updated":"2020-09-26T23:42:37.000Z","comments":true,"path":"ICML20-GCN/","link":"","permalink":"https://tianlong-chen.github.io/ICML20-GCN/","excerpt":"","text":"When Does Self-Supervision Help Graph Convolutional Networks?[Paper] [Code] AbstractSelf-supervision as an emerging technique has been employed to train convolutional neural networks (CNNs) for more transferrable, generalizable, and robust representation learning of images. Its introduction to graph convolutional networks (GCNs) operating on graph data is however rarely explored. In this study, we report the first systematic exploration and assessment of incorporating self-supervision into GCNs. We first elaborate three mechanisms to incorporate self-supervision into GCNs, analyze the limitations of pretraining &amp; finetuning and self-training, and proceed to focus on multi-task learning. Moreover, we propose to investigate threenovel self-supervised learning tasks for GCNs with theoretical rationales and numerical comparisons. Lastly, we further integrate multi-task self-supervision into graph adversarial training. Our results show that, with properly designed task forms and incorporation mechanisms, self-supervision benefits GCNs in gaining more generalizability and robustness. Our codes are available at https://github.com/Shen-Lab/SS-GCNs .","categories":[{"name":"ICML'20","slug":"ICML-20","permalink":"https://tianlong-chen.github.io/categories/ICML-20/"}],"tags":[{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"}]},{"title":"(ICML 2020) Self-PU, Self Boosted and Calibrated Positive-Unlabeled Training","slug":"ICML20-Self","date":"2020-07-11T05:00:00.000Z","updated":"2020-09-26T23:42:46.000Z","comments":true,"path":"ICML20-Self/","link":"","permalink":"https://tianlong-chen.github.io/ICML20-Self/","excerpt":"","text":"Self-PU: Self Boosted and Calibrated Positive-Unlabeled Training[Paper] [Code] AbstractMany real-world applications have to tackle the Positive-Unlabeled (PU) learning problem,i.e.,learning binary classifiers from a large amountof unlabeled data and a few labeled positive examples. While current state-of-the-art methodsemploy importance reweighting to design various risk estimators, they ignored the learning capability of the model itself, which could haveprovided reliable supervision. This motivatesus to propose a novel Self-PU learning framework, which seamlessly integrates PU learningand self-training. Self-PU highlights three “self”-oriented building blocks: a self-paced training algorithm that adaptively discovers and augments confident positive/negative examples as the training proceeds; a self-calibrated instance-aware loss; and a self-distillation scheme that introduces teacher-students learning as an effectiveregularization for PU learning. We demonstratethe state-of-the-art performance of Self-PU oncommon PU learning benchmarks (MNIST and CIFAR-10), which compare favorably against thelatest competitors. Moreover, we study a real-world application of PU learning,i.e., classifying brain images of Alzheimer’s Disease. Self-PU obtains significantly improved results on the renowned Alzheimer’s Disease Neuroimaging Initiative (ADNI) database over existing methods.","categories":[{"name":"ICML'20","slug":"ICML-20","permalink":"https://tianlong-chen.github.io/categories/ICML-20/"}],"tags":[{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"PU Learning","slug":"PU-Learning","permalink":"https://tianlong-chen.github.io/tags/PU-Learning/"},{"name":"Self Training","slug":"Self-Training","permalink":"https://tianlong-chen.github.io/tags/Self-Training/"}]},{"title":"(CVPR 2020) Adversarial Robustness, From Self-Supervised Pre-Training to Fine-Tuning","slug":"CVPR20-Selfie","date":"2020-06-18T05:00:00.000Z","updated":"2020-07-22T04:15:58.000Z","comments":true,"path":"CVPR20-Selfie/","link":"","permalink":"https://tianlong-chen.github.io/CVPR20-Selfie/","excerpt":"","text":"Adversarial Robustness: From Self-Supervised Pre-Training to Fine-Tuning[Paper] [Code] AbstractPretrained models from self-supervision are prevalently used in fine-tuning downstream tasks faster or for better accuracy. However, gaining robustness from pretraining is left unexplored. We introduce adversarial training into self- supervision, to provide general-purpose robust pretrained models for the first time. We find these robust pretrained models can benefit the subsequent fine-tuning in two ways: i) boosting final model robustness; ii) saving the computation cost, if proceeding towards adversarial fine-tuning. We conduct extensive experiments to demonstrate that the proposed framework achieves large performance margins (e.g., 3.83% on robust accuracy and 1.3% on standard accuracy, on the CIFAR-10 dataset), compared with the conventional end-to-end adversarial training baseline. Moreover, we find that different self-supervised pretrained models have diverse adversarial vulnerability. It inspires us to ensemble several pretraining tasks, which boosts robustness more. Our ensemble strategy contributes to a further improvement of 3.59% on robust accuracy, while maintaining a slightly higher standard accuracy on CIFAR-10. Our codes are available at https://github.com/TAMU-VITA/Adv-SS-Pretraining .","categories":[{"name":"CVPR'20","slug":"CVPR-20","permalink":"https://tianlong-chen.github.io/categories/CVPR-20/"}],"tags":[{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"}]},{"title":"(CVPR 2020) L^2-GCN, Layer-Wise and Learned Efficient Training of Graph Convolutional Networks","slug":"CVPR20-GCN","date":"2020-06-17T05:00:00.000Z","updated":"2020-09-26T23:41:47.000Z","comments":true,"path":"CVPR20-GCN/","link":"","permalink":"https://tianlong-chen.github.io/CVPR20-GCN/","excerpt":"","text":"L$^2$-GCN: Layer-Wise and Learned Efficient Training of Graph Convolutional Networks[Paper] [Code] AbstractGraph convolution networks (GCN) are increasingly popular in many applications, yet remain notoriously hard to train over large graph datasets. They need to compute node representations recursively from their neighbors. Current GCN training algorithms suffer from either high computational costs that grow exponentially with the number of layers, or high memory usage for loading the entire graph and node embeddings. In this paper, we propose a novel efficient layer-wise training framework for GCN (L-GCN), that disentangles feature aggregation and feature transformation during training, hence greatly reducing time and memory complexities. We present theoretical analysis for L-GCN under the graph isomorphism framework, that L-GCN leads to as powerful GCNs as the more costly conventional training algorithm does, under mild conditions. We further propose L$^2$-GCN, which learns a controller for each layer that can automatically adjust the training epochs per layer in L-GCN. Experiments show that L-GCN is faster than state-of-the-arts by at least an order of magnitude, with a consistent of memory usage not dependent on dataset size, while maintaining comparable prediction performance. With the learned controller, L$^2$-GCN can further cut the training time in half. Our codes are available at https://github.com/Shen-Lab/L2-GCN .","categories":[{"name":"CVPR'20","slug":"CVPR-20","permalink":"https://tianlong-chen.github.io/categories/CVPR-20/"}],"tags":[{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"}]},{"title":"(CVPRW 2020) Focus Longer to See Better, Recursively Refined Attention for Fine-Grained Image Classification","slug":"CVPRW20","date":"2020-06-16T05:00:00.000Z","updated":"2020-08-20T03:31:23.000Z","comments":true,"path":"CVPRW20/","link":"","permalink":"https://tianlong-chen.github.io/CVPRW20/","excerpt":"","text":"Focus Longer to See Better: Recursively Refined Attention for Fine-Grained Image Classification[Paper] [Code] AbstractDeep Neural Network has shown great strides in the coarse-grained image classification task. It was in part due to its strong ability to extract discriminative feature representations from the images. However, the marginal visual difference between different classes in fine-grained images makes this very task harder. In this paper, we tried to focus on these marginal differences to extract more representative features. Similar to human vision, our network repetitively focuses on parts of images to spot small discriminative parts among the classes. Moreover, we show through interpretability techniques how our network focus changes from coarse to fine details. Through our experiments, we also show that a simple attention model can aggregate (weighted) these finer details to focus on the most dominant discriminative part of the image. Our network uses only image-level labels and does not need bounding box/part annotation information. Further, the simplicity of our network makes it an easy plug-n-play module. Apart from providing interpretability, our network boosts the performance (up to 2%) when compared to its baseline counterparts. Our codebase is available at https://github.com/TAMU-VITA/Focus-Longer-to-See-Better .","categories":[{"name":"CVPRW'20","slug":"CVPRW-20","permalink":"https://tianlong-chen.github.io/categories/CVPRW-20/"}],"tags":[{"name":"Attention","slug":"Attention","permalink":"https://tianlong-chen.github.io/tags/Attention/"},{"name":"Fine-Grained Classification","slug":"Fine-Grained-Classification","permalink":"https://tianlong-chen.github.io/tags/Fine-Grained-Classification/"}]},{"title":"(ArXiv Preprint 2020) Can 3D Adversarial Logos Cloak Humans?","slug":"Preprint-ADV","date":"2020-06-15T05:00:00.000Z","updated":"2020-08-18T01:33:03.000Z","comments":true,"path":"Preprint-ADV/","link":"","permalink":"https://tianlong-chen.github.io/Preprint-ADV/","excerpt":"","text":"Can 3D Adversarial Logos Cloak Humans?[Paper] [Code] AbstractWith the trend of adversarial attacks, researchers attempt to fool trained object detectors in 2D scenes. Among many of them, an intriguing new form of attack with potential real-world usage is to append adversarial patches (e.g. logos) to images. Nevertheless, much less have we known about adversarial attacks from 3D rendering views, which is essential for the attack to be persistently strong in the physical world. This paper presents a new 3D adversarial logo attack: we construct an arbitrary shape logo from a 2D texture image and map this image into a 3D adversarial logo via a texture mapping called logo transformation. The resulting 3D adversarial logo is then viewed as an adversarial texture enabling easy manipulation of its shape and position. This greatly extends the versatility of adversarial training for computer graphics synthesized imagery. Contrary to the traditional adversarial patch, this new form of attack is mapped into the 3D object world and back-propagates to the 2D image domain through differentiable rendering. In addition, and unlike existing adversarial patches, our new 3D adversarial logo is shown to fool state-of-the-art deep object detectors robustly under model rotations, leading to one step further for realistic attacks in the physical world. Our codes are available at https://github.com/TAMU-VITA/3D_Adversarial_Logo .","categories":[{"name":"ArXiv Preprint","slug":"ArXiv-Preprint","permalink":"https://tianlong-chen.github.io/categories/ArXiv-Preprint/"}],"tags":[{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Detection","slug":"Detection","permalink":"https://tianlong-chen.github.io/tags/Detection/"},{"name":"3D Mesh","slug":"3D-Mesh","permalink":"https://tianlong-chen.github.io/tags/3D-Mesh/"}]},{"title":"(LREC 2020) Dataset and Enhanced Model for Eligibility Criteria-to-SQL Semantic Parsing","slug":"LREC20","date":"2020-05-11T05:00:00.000Z","updated":"2020-07-22T02:41:25.000Z","comments":true,"path":"LREC20/","link":"","permalink":"https://tianlong-chen.github.io/LREC20/","excerpt":"","text":"Dataset and Enhanced Model for Eligibility Criteria-to-SQL Semantic Parsing[Paper] AbstractClinical trials often require that patients meet eligibility criteria (e.g., have specific conditions) to ensure the safety and the effectiveness of studies. However, retrieving eligible patients for a trial from the electronic health record (EHR) database remains a challenging task for clinicians since it requires not only medical knowledge about eligibility criteria, but also an adequate understanding of structured query language (SQL). In this paper, we introduce a new dataset that includes the first-of-its-kind eligibility-criteria corpus and the corresponding queries for criteria-to-sql (Criteria2SQL), a task translating the eligibility criteria to executable SQL queries. Compared to existing datasets, the queries in the dataset here are derived from the eligibility criteria of clinical trials and include Order-sensitive, Counting-based, and Boolean-type cases which are not seen before. In addition to the dataset, we propose a novel neural semantic parser as a strong baseline model. Extensive experiments show that the proposed parser outperforms existing state-of-the-art general-purpose text-to-sql models while highlighting the challenges presented by the new dataset. The uniqueness and the diversity of the dataset leave a lot of research opportunities for future improvement.","categories":[{"name":"LREC'20","slug":"LREC-20","permalink":"https://tianlong-chen.github.io/categories/LREC-20/"}],"tags":[{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://tianlong-chen.github.io/tags/Natural-Language-Processing/"},{"name":"BERT","slug":"BERT","permalink":"https://tianlong-chen.github.io/tags/BERT/"}]},{"title":"(ICLR 2020) Triple Wins, Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference","slug":"ICLR20-Triple","date":"2020-05-05T05:00:00.000Z","updated":"2020-09-26T23:42:26.000Z","comments":true,"path":"ICLR20-Triple/","link":"","permalink":"https://tianlong-chen.github.io/ICLR20-Triple/","excerpt":"","text":"Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference[Paper] [Code] AbstractDeep networks were recently suggested to face the odds between accuracy (on clean natural images) and robustness (on adversarially perturbed images) (Tsipras et al., 2019). Such a dilemma is shown to be rooted in the inherently higher sample complexity (Schmidt et al., 2018) and/or model capacity (Nakkiran, 2019), for learning a high-accuracy and robust classifier. In view of that, give a classification task, growing the model capacity appears to help draw a win-win between accuracy and robustness, yet at the expense of model size and latency, therefore posing challenges for resource-constrained applications. Is it possible to co-design model accuracy, robustness and efficiency to achieve their triple wins? This paper studies multi-exit networks associated with input-adaptive efficient inference, showing their strong promise in achieving a “sweet point” in co- optimizing model accuracy, robustness and efficiency. Our proposed solution, dubbed Robust Dynamic Inference Networks (RDI-Nets), allows for each input (either clean or adversarial) to adaptively choose one of the multiple output layers (early branches or the final one) to output its prediction. That multi-loss adaptivity adds new variations and flexibility to adversarial attacks and defenses, on which we present a systematical investigation. We show experimentally that by equipping existing backbones with such robust adaptive inference, the resulting RDI-Nets can achieve better accuracy and robustness, yet with over 30% computational savings, compared to the defended original models.","categories":[{"name":"ICLR'20","slug":"ICLR-20","permalink":"https://tianlong-chen.github.io/categories/ICLR-20/"}],"tags":[{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"Adaptive Inference","slug":"Adaptive-Inference","permalink":"https://tianlong-chen.github.io/tags/Adaptive-Inference/"}]},{"title":"(ICLR 2020) I am Going MAD, Maximum Discrepancy Competition for Comparing Classifiers Adaptively","slug":"ICLR20-MAD","date":"2020-05-04T05:00:00.000Z","updated":"2020-07-22T06:35:51.000Z","comments":true,"path":"ICLR20-MAD/","link":"","permalink":"https://tianlong-chen.github.io/ICLR20-MAD/","excerpt":"","text":"I am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively[Paper] [Code] AbstractThe learning of hierarchical representations for image classification has experienced an impressive series of successes due in part to the availability of large-scale labeled data for training. On the other hand, the trained classifiers have traditionally been evaluated on small and fixed sets of test images, which are deemed to be extremely sparsely distributed in the space of all natural images. It is thus questionable whether recent performance improvements on the excessively re-used test sets generalize to real-world natural images with much richer content variations. Inspired by efficient stimulus selection for testing perceptual models in psychophysical and physiological studies, we present an alternative framework for comparing image classifiers, which we name the MAximum Discrepancy (MAD) competition. Rather than comparing image classifiers using fixed test images, we adaptively sample a small test set from an arbitrarily large corpus of unlabeled images so as to maximize the discrepancies between the classifiers, measured by the distance over WordNet hierarchy. Human labeling on the resulting model-dependent image sets reveals the relative performance of the competing classifiers, and provides useful insights on potential ways to improve them. We report the MAD competition results of eleven ImageNet classifiers while noting that the framework is readily extensible and cost-effective to add future classifiers into the competition. Codes can be found at https://github.com/TAMU-VITA/MAD .","categories":[{"name":"ICLR'20","slug":"ICLR-20","permalink":"https://tianlong-chen.github.io/categories/ICLR-20/"}],"tags":[{"name":"Model Comparison","slug":"Model-Comparison","permalink":"https://tianlong-chen.github.io/tags/Model-Comparison/"}]},{"title":"(WACV 2020) Calibrated Domain-Invariant Learning for Highly Generalizable Large Scale Re-Identification","slug":"WACV20","date":"2020-03-01T06:00:00.000Z","updated":"2020-07-22T07:38:53.000Z","comments":true,"path":"WACV20/","link":"","permalink":"https://tianlong-chen.github.io/WACV20/","excerpt":"","text":"Calibrated Domain-Invariant Learning for Highly Generalizable Large Scale Re-Identification[Paper] [Code] AbstractMany real-world applications, such as city scale traffic monitoring and control, requires large scale re-identification. However, previous ReID methods often failed to address two limitations in existing ReID benchmarks, i.e., low spatiotemporal coverage and sample imbalance. Notwithstanding their demonstrated success in every single benchmark, they have difficulties in generalizing to unseen environments. As a re∂sult, these methods are less applicable in a large scale setting due to poor generalization. In seek for a highly generaliz- able large-scale ReID method, we present an adversarial domain-invariant feature learning framework (ADIN) that explicitly learns to separate identity-related features from challenging variations, where for the first time “free” anno- tations in ReID data such as video timestamp and camera index are utilized. Furthermore, we find that the imbalance of nuisance classes jeopardizes the adversarial training, and for mitigation we propose a calibrated adversarial loss that is attentive to nuisance distribution. Experiments on existing large-scale person/vehicle ReID datasets demonstrate that ADIN learns more robust and generalizable representations, as evidenced by its outstanding direct transfer performance across datasets, which is a criterion that can better measure the generalizability of large scale Re-ID methods.","categories":[{"name":"WACV'20","slug":"WACV-20","permalink":"https://tianlong-chen.github.io/categories/WACV-20/"}],"tags":[{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Person Re-Identification","slug":"Person-Re-Identification","permalink":"https://tianlong-chen.github.io/tags/Person-Re-Identification/"},{"name":"Adversarial Learning","slug":"Adversarial-Learning","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Learning/"}]},{"title":"(NeurIPS 2019) Learning to Optimize in Swarms","slug":"NIPS19","date":"2019-12-06T06:00:00.000Z","updated":"2020-07-22T06:33:33.000Z","comments":true,"path":"NIPS19/","link":"","permalink":"https://tianlong-chen.github.io/NIPS19/","excerpt":"","text":"Learning to Optimize in Swarms[Paper] [Code] AbstractLearning to optimize has emerged as a powerful framework for various optimization and machine learning tasks. Current such “meta-optimizers” often learn in the space of continuous optimization algorithms that are point-based and uncertainty- unaware. To overcome the limitations, we propose a meta-optimizer that learns in the algorithmic space of both point-based and population-based optimization algorithms. The meta-optimizer targets at a meta-loss function consisting of both cumulative regret and entropy. Specifically, we learn and interpret the update formula through a population of LSTMs embedded with sample- and feature-level attentions. Meanwhile, we estimate the posterior directly over the global optimum and use an uncertainty measure to help guide the learning process. Empirical results over non-convex test functions and the protein-docking application demonstrate that this new meta-optimizer outperforms existing competitors. The codes are publicly available at: https://github.com/Shen-Lab/LOIS.","categories":[{"name":"NeurIPS'19","slug":"NeurIPS-19","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-19/"}],"tags":[{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Attention","slug":"Attention","permalink":"https://tianlong-chen.github.io/tags/Attention/"}]},{"title":"(ICCV 2019) ABD-Net, Attentive but Diverse Person Re-Identification.","slug":"ICCV19-ABD","date":"2019-10-27T05:00:00.000Z","updated":"2020-07-22T06:30:09.000Z","comments":true,"path":"ICCV19-ABD/","link":"","permalink":"https://tianlong-chen.github.io/ICCV19-ABD/","excerpt":"","text":"ABD-Net: Attentive but Diverse Person Re-Identification[Paper] [Code] AbstractAttention mechanisms have been found effective for person re-identification (Re-ID). However, the learned “attentive” features are often not naturally uncorrelated or “diverse”, which compromises the retrieval performance based on the Euclidean distance. We advocate the com- plementary powers of attention and diversity for Re-ID, by proposing an Attentive but Diverse Network (ABD-Net). ABD-Net seamlessly integrates attention modules and diversity regularizations throughout the entire network to learn features that are representative, robust, and more dis- criminative. Specifically, we introduce a pair of comple- mentary attention modules, focusing on channel aggregation and position awareness, respectively. Then, we plug in a novel orthogonality constraint that efficiently enforces di- versity on both hidden activations and weights. Through an extensive set of ablation study, we verify that the attentive and diverse terms each contributes to the perfor- mance boosts of ABD-Net. It consistently outperforms exist- ing state-of-the-art methods on there popular person Re-ID benchmarks.","categories":[{"name":"ICCV'19","slug":"ICCV-19","permalink":"https://tianlong-chen.github.io/categories/ICCV-19/"}],"tags":[{"name":"Attention","slug":"Attention","permalink":"https://tianlong-chen.github.io/tags/Attention/"},{"name":"Person Re-Identification","slug":"Person-Re-Identification","permalink":"https://tianlong-chen.github.io/tags/Person-Re-Identification/"}]},{"title":"(ICCVW 2019) Cross-Model Person Search, A Coarse-to-FineFramework using Bi-directional Text-Image Matching","slug":"ICCVW19","date":"2019-10-26T05:00:00.000Z","updated":"2020-09-26T23:42:13.000Z","comments":true,"path":"ICCVW19/","link":"","permalink":"https://tianlong-chen.github.io/ICCVW19/","excerpt":"","text":"Cross-Model Person Search: A Coarse-to-FineFramework using Bi-directional Text-Image Matching[Paper] AbstractSearching person images from a gallery based on natu- ral language descriptions remains to be a challenging and under-explored cross-modal retrieval problem. To improve the accuracy off an image-based retrieval task, e.g., person re-identification (Person Re-Id), re-ranking is known to be an effective post-processing tool. In this paper, we extend re-ranking from uni-modal retrieval to cross-modal retrieval for the first time, and develop a bi-directional coarse-to-fine framework (BCF) for cross-modal person search. Built on a recent state-of-the-art Person Re- Id model , BCF exploits first text-to-image and then image-to-text relevance, in a two-stage refinement fash- ion. BCF ranks competitively against a strong baseline on the newly-introduced WIDER Person Search dataset , boosting validation set performance by 9.01% (top-1) / 3.87 % (mAP) for val1 and 6.60% (top-1) / 3.49% (mAP) for val2, respectively. With a high score, our solution ranks competitively in the ICCV 2019 WIDER Person Search by Language Challenge.","categories":[{"name":"ICCVW'19","slug":"ICCVW-19","permalink":"https://tianlong-chen.github.io/categories/ICCVW-19/"}],"tags":[{"name":"Person Re-Identification","slug":"Person-Re-Identification","permalink":"https://tianlong-chen.github.io/tags/Person-Re-Identification/"},{"name":"Multi-Modality","slug":"Multi-Modality","permalink":"https://tianlong-chen.github.io/tags/Multi-Modality/"}]}],"categories":[{"name":"AAAI'22","slug":"AAAI-22","permalink":"https://tianlong-chen.github.io/categories/AAAI-22/"},{"name":"WSDM'22","slug":"WSDM-22","permalink":"https://tianlong-chen.github.io/categories/WSDM-22/"},{"name":"ArXiv Preprint","slug":"ArXiv-Preprint","permalink":"https://tianlong-chen.github.io/categories/ArXiv-Preprint/"},{"name":"NeurIPS'21","slug":"NeurIPS-21","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-21/"},{"name":"ICML'21","slug":"ICML-21","permalink":"https://tianlong-chen.github.io/categories/ICML-21/"},{"name":"CVPR'21","slug":"CVPR-21","permalink":"https://tianlong-chen.github.io/categories/CVPR-21/"},{"name":"CVPRW'21","slug":"CVPRW-21","permalink":"https://tianlong-chen.github.io/categories/CVPRW-21/"},{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"},{"name":"ICASSP'21","slug":"ICASSP-21","permalink":"https://tianlong-chen.github.io/categories/ICASSP-21/"},{"name":"AAAIW'21","slug":"AAAIW-21","permalink":"https://tianlong-chen.github.io/categories/AAAIW-21/"},{"name":"NeurIPS'20","slug":"NeurIPS-20","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-20/"},{"name":"InterSpeech'20","slug":"InterSpeech-20","permalink":"https://tianlong-chen.github.io/categories/InterSpeech-20/"},{"name":"ECCV'20","slug":"ECCV-20","permalink":"https://tianlong-chen.github.io/categories/ECCV-20/"},{"name":"ICML'20","slug":"ICML-20","permalink":"https://tianlong-chen.github.io/categories/ICML-20/"},{"name":"CVPR'20","slug":"CVPR-20","permalink":"https://tianlong-chen.github.io/categories/CVPR-20/"},{"name":"CVPRW'20","slug":"CVPRW-20","permalink":"https://tianlong-chen.github.io/categories/CVPRW-20/"},{"name":"LREC'20","slug":"LREC-20","permalink":"https://tianlong-chen.github.io/categories/LREC-20/"},{"name":"ICLR'20","slug":"ICLR-20","permalink":"https://tianlong-chen.github.io/categories/ICLR-20/"},{"name":"WACV'20","slug":"WACV-20","permalink":"https://tianlong-chen.github.io/categories/WACV-20/"},{"name":"NeurIPS'19","slug":"NeurIPS-19","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-19/"},{"name":"ICCV'19","slug":"ICCV-19","permalink":"https://tianlong-chen.github.io/categories/ICCV-19/"},{"name":"ICCVW'19","slug":"ICCVW-19","permalink":"https://tianlong-chen.github.io/categories/ICCVW-19/"}],"tags":[{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Contrasive Learning","slug":"Contrasive-Learning","permalink":"https://tianlong-chen.github.io/tags/Contrasive-Learning/"},{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"Vision Transformer","slug":"Vision-Transformer","permalink":"https://tianlong-chen.github.io/tags/Vision-Transformer/"},{"name":"Adversarial Learning","slug":"Adversarial-Learning","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Learning/"},{"name":"Generative Adversarial Networks","slug":"Generative-Adversarial-Networks","permalink":"https://tianlong-chen.github.io/tags/Generative-Adversarial-Networks/"},{"name":"Data Efficiency","slug":"Data-Efficiency","permalink":"https://tianlong-chen.github.io/tags/Data-Efficiency/"},{"name":"Model Verification","slug":"Model-Verification","permalink":"https://tianlong-chen.github.io/tags/Model-Verification/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Fairness","slug":"Fairness","permalink":"https://tianlong-chen.github.io/tags/Fairness/"},{"name":"Graph Augmentation","slug":"Graph-Augmentation","permalink":"https://tianlong-chen.github.io/tags/Graph-Augmentation/"},{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Detection","slug":"Detection","permalink":"https://tianlong-chen.github.io/tags/Detection/"},{"name":"Segmentation","slug":"Segmentation","permalink":"https://tianlong-chen.github.io/tags/Segmentation/"},{"name":"Image Quality Assessment","slug":"Image-Quality-Assessment","permalink":"https://tianlong-chen.github.io/tags/Image-Quality-Assessment/"},{"name":"Model Comparison","slug":"Model-Comparison","permalink":"https://tianlong-chen.github.io/tags/Model-Comparison/"},{"name":"Binary Neural Network","slug":"Binary-Neural-Network","permalink":"https://tianlong-chen.github.io/tags/Binary-Neural-Network/"},{"name":"Normalization Free","slug":"Normalization-Free","permalink":"https://tianlong-chen.github.io/tags/Normalization-Free/"},{"name":"Batch Normalization","slug":"Batch-Normalization","permalink":"https://tianlong-chen.github.io/tags/Batch-Normalization/"},{"name":"Knowledge Distillation","slug":"Knowledge-Distillation","permalink":"https://tianlong-chen.github.io/tags/Knowledge-Distillation/"},{"name":"Lifelong Learning","slug":"Lifelong-Learning","permalink":"https://tianlong-chen.github.io/tags/Lifelong-Learning/"},{"name":"Privacy Preserving","slug":"Privacy-Preserving","permalink":"https://tianlong-chen.github.io/tags/Privacy-Preserving/"},{"name":"Curriculum Learning","slug":"Curriculum-Learning","permalink":"https://tianlong-chen.github.io/tags/Curriculum-Learning/"},{"name":"Imitation Learning","slug":"Imitation-Learning","permalink":"https://tianlong-chen.github.io/tags/Imitation-Learning/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://tianlong-chen.github.io/tags/Natural-Language-Processing/"},{"name":"BERT","slug":"BERT","permalink":"https://tianlong-chen.github.io/tags/BERT/"},{"name":"Speaker Recognition","slug":"Speaker-Recognition","permalink":"https://tianlong-chen.github.io/tags/Speaker-Recognition/"},{"name":"Neural Archtecture Search","slug":"Neural-Archtecture-Search","permalink":"https://tianlong-chen.github.io/tags/Neural-Archtecture-Search/"},{"name":"Adaptation","slug":"Adaptation","permalink":"https://tianlong-chen.github.io/tags/Adaptation/"},{"name":"PU Learning","slug":"PU-Learning","permalink":"https://tianlong-chen.github.io/tags/PU-Learning/"},{"name":"Self Training","slug":"Self-Training","permalink":"https://tianlong-chen.github.io/tags/Self-Training/"},{"name":"Attention","slug":"Attention","permalink":"https://tianlong-chen.github.io/tags/Attention/"},{"name":"Fine-Grained Classification","slug":"Fine-Grained-Classification","permalink":"https://tianlong-chen.github.io/tags/Fine-Grained-Classification/"},{"name":"3D Mesh","slug":"3D-Mesh","permalink":"https://tianlong-chen.github.io/tags/3D-Mesh/"},{"name":"Adaptive Inference","slug":"Adaptive-Inference","permalink":"https://tianlong-chen.github.io/tags/Adaptive-Inference/"},{"name":"Person Re-Identification","slug":"Person-Re-Identification","permalink":"https://tianlong-chen.github.io/tags/Person-Re-Identification/"},{"name":"Multi-Modality","slug":"Multi-Modality","permalink":"https://tianlong-chen.github.io/tags/Multi-Modality/"}]}