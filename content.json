{"meta":{"title":"Tianlong Chen (陈天龙)","subtitle":"What does not kill you makes you stronger","description":"Make the change that you want to see in the world","author":"Tianlong Chen (陈天龙)","url":"https://Tianlong-Chen.github.io","root":"/"},"pages":[{"title":"categories","date":"2018-08-01T05:00:00.000Z","updated":"2020-07-22T02:09:00.133Z","comments":true,"path":"categories/index.html","permalink":"https://tianlong-chen.github.io/categories/index.html","excerpt":"","text":""},{"title":"Hello World!","date":"2021-02-08T03:30:46.341Z","updated":"2021-02-08T03:30:46.334Z","comments":true,"path":"about/index.html","permalink":"https://tianlong-chen.github.io/about/index.html","excerpt":"","text":"I am currently a third-year Ph.D. student of Electrical and Computer Engineering (DICE) at VITA, The University of Texas at Austin, advised by Dr. Zhangyang (Atlas) Wang. My research interests include AutoML, Adversarial Robustness, Self-Supervision and Graph Neural Networks. [Resume] [Google Scholar] [Publication] Education [Aug. 2020 - Present] Ph.D. student in Electrical and Computer Engineering, DICE, The University of Texas at Austin [Aug. 2018 - Aug. 2020] Ph.D. student in Computer Science, Texas A&amp;M University [Aug. 2013 - Jun. 2017] B.S.c. in Applied Mathematics, School of the Gifted Young, University of Science and Technology of China [Aug. 2015 - Jun. 2017] B.Eng. (Dual) in Computer Science, School of the Gifted Young, University of Science and Technology of China Publication[*equal contribution] 2021 [ICLR’21] Robust Overfitting may be mitigated by properly learned smootheningT. Chen*, Z. Zhang*, S. Liu, S. Chang, and Z. Wang. [Paper] [Code] [Abstract] [ICLR’21] Long Live the Lottery: The Existence of Winning Tickets in Lifelong LearningT. Chen*, Z. Zhang*, S. Liu, S. Chang, and Z. Wang. [Paper] [Code] [Abstract] [ICLR’21] GANs Can Play Lottery Tickets TooX. Chen, Z. Zhang, Y. Sui, and T. Chen. [Paper] [Code] [Abstract] [ICLR’21 Spotlight Oral] Undistillable: Making A Nasty Teacher That CANNOT teach studentsH. Ma, T. Chen, T. Hu, C. You, X. Xie, and Z. Wang. [Paper] [Code] [Abstract] [ICLR’21] Learning A Minimax Optimizer: A Pilot StudyJ. Shen, X. Chen, H. Heaton, T. Chen, J. Liu, W. Yin, and Z. Wang. [Paper] [Code] [Abstract] [ICASSP’21] VGAI: End-to-End Learning of Vision-Based Decentralized Controllers for Robust SwarmsT. Hu, F. Gama, T. Chen, Z. Wang, A. Ribeiro, and B. Sadler. [Paper] [Code] [Abstract] [AAAIW’21 Oral] AR-Stock: Deep Augmented Relational Stock PredictionT. Wei, Y. You, and T. Chen. [Paper] [Code] [Abstract] 2020 [NeurIPS’20 Spotlight Oral] Training Stronger Baselines for Learning to OptimizeT. Chen*, W. Zhang*, J. Zhou, S. Chang, S. Liu, L. Amini, and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’20] The Lottery Ticket Hypothesis for Pre-trained BERT NetworksT. Chen, J. Frankle, S. Chang, S. Liu, Y. Zhang, Z. Wang, and M. Carbin. [Paper] [Code] [Abstract] [NeurIPS’20] Once-for-All Adversarial Training: In-Situ Trade off between Robustness and Accuracy for FreeH. Wang*, T. Chen*, S. Gui, T. Hu, J. Liu, and Z. Wang. [Paper] [Code] [Abstract] [NeurIPS’20] Graph Contrastive Learning with AugmentationsY. You*, T. Chen*, Y. Sui, T. Chen, Z. Wang, and S. Yang. [Paper] [Code] [Abstract] [NeurIPS’20] Robust Pre-Training by Adversarial Contrastive LearningZ. Jiang, T. Chen, T. Chen, and Z. Wang. [Paper] [Code] [Abstract] [InterSpeech’20] AutoSpeech: Neural Architecture Search for Speaker RecognitionS. Ding*, T. Chen*, X. Gong, W. Zha, and Z. Wang. [Paper] [Code] [Abstract] [ECCV’20] HALO: Hardware-Aware Learning to Optimize C. Li*, T. Chen*, H. You, Z. Wang, and Y. Lin. [Paper] [Code] [Abstract] [ICML’20] When Does Self-Supervision Help Graph Convolutional Networks?Y. You*, T. Chen*, Z. Wang, and Y. Shen. [Paper] [Code] [Abstract] [ICML’20] Self-PU: Self Boosted and Calibrated Positive-Unlabeled TrainingX. Chen, W. Chen, T. Chen, Y. Yuan, C. Gong, K. Chen, and Z. Wang. [Paper] [Code] [Abstract] [CVPR’20] Adversarial Robustness: From Self-Supervised Pre-Training to Fine-TuningT. Chen, S. Liu, S. Chang, Y. Cheng, L. Amini, and Z. Wang. [Paper] [Code] [Abstract] [CVPR’20] L^2-GCN: Layer-Wise and Learned Efficient Training of Graph Convolutional NetworksY. You*, T. Chen*, Z. Wang, and Y. Shen. [Paper] [Code] [Abstract] [ICLR’20] Triple Wins: Boosting Accuracy, Robustness and Efficiency by Enabling Input-Adaptive InferenceT. Hu*, T. Chen*, H. Wang, and Z. Wang. [Paper] [Code] [Abstract] [ICLR’20] I am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively H. Wang, T. Chen, Z. Wang, and K. Ma. [Paper] [Code] [Abstract] [WACV’20] Calibrated Domain-Invariant Learning for Highly Generalizable Large Scale Re-IdentificationY. Yuan, W. Chen, T. Chen, Y. Yang, Z. Ren, Z. Wang and G. Hua. [Paper] [Code] [Abstract] [LREC’20] Dataset and Enhanced Model for Eligibility Criteria-to-SQL Semantic ParsingX. Yu, T. Chen, Z. Yu, H. Li, Y. Yang, X. Jiang and A. Jiang. [Paper] [Abstract] [CVPRW’20] Focus Longer to See Better: Recursively Refined Attention for Fine-Grained Image ClassificationP. Shroff, T. Chen, Y. Wei, and Z. Wang. [Paper] [Code] [Abstract] 2019 [NeurIPS’19] Learning to Optimize in SwarmsY. Cao, T. Chen, Z. Wang, and S. Yang. [Paper] [Code] [Abstract] [ICCV’19] ABD-Net: Attentive but Diverse Person Re-IdentificationT. Chen, S. Ding, J. Xie, Y. Yuan, W. Chen, Y. Yang, Z. Ren, and Z. Wang. [Paper] [Code] [Abstract] [ICCVW’19] Cross-Model Person Search: A Coarse-to-FineFramework using Bi-directional Text-Image MatchingX. Yu*, T. Chen*, Y. Yang, M. Mugo, and Z. Wang. [Paper] [Abstract] Technical Reports [ArXiv Preprint’21] The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision ModelsT. Chen, J. Frankle, S. Chang, S. Liu, Y. Zhang, Z. Wang, and M. Carbin. [Paper] [Code] [Abstract] [ArXiv Preprint’21] Good Students Play Big Lottery BetterH. Ma, T. Chen, T. Hu, C. You, X. Xie, and Z. Wang. [Paper] [Code] [Abstract] [ArXiv Preprint’20] Can 3D Adversarial Logos Cloak Humans?Y. Wang, J. Zhou, T.Chen, S. Liu, S. Chang, C. Bajaj, and Z. Wang. [Paper] [Code] [Abstract] Experience Facebook Research, Research Intern [May. 2021 - Aug. 2021] Mentor: Dr. Hanning (Eric) Zhou, Dr. Xing Wang Microsoft Research Redmond, Part-time Research Intern [Sep. 2020 - Dec. 2020] Mentor: Dr. Yu Cheng, Dr. Zhe Gan Microsoft Research Redmond, Research Intern [May. 2020 - Aug. 2020] Mentor: Dr. Yu Cheng, Dr. Zhe Gan, Dr. Yu Hu Walmart Technology, Research Intern [May. 2019 - Aug. 2019] Mentor: Dr. Yang Yang University of Science and Technology of China, Research Assistant [Jun. 2017 - Jun. 2018] Mentor: Dr. Zhouwang Yang Harvard University, Research Intern [Jul. 2016 - Jan. 2017] Mentor: Dr. Gil Alterovitz Research Award 3rd Place, ICCV 2019 WIDER Challenge Track 4, Oct. 2019 First Place, Walmart-TAMU Person Re-Identification (Re-ID) Competition, May. 2018 NeurIPS 2019 Student Travel Award, Dec. 2019 Media Coverage Shrinking massive neural networks used to model language, MIT News (Featured), Dec. 2020 Fooling deep neural networks for object detection with adversarial 3-D logos, Tech Xplore, Jul. 2020 More About Me I am a big fan of Pokemon. Playing Pokemon Go is one of my daily activities. I also enjoy Hip-Hop and Country music. Air (艾热) is one of my favorite Chinese Hip-Hop stars."},{"title":"Topics","date":"2018-08-01T05:00:00.000Z","updated":"2020-07-22T07:23:22.839Z","comments":true,"path":"tags/index.html","permalink":"https://tianlong-chen.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"(ICLR 2021) Robust Overfitting may be mitigated by properly learned smoothening","slug":"ICLR21-ADV","date":"2021-05-02T05:00:00.000Z","updated":"2021-02-08T01:52:34.720Z","comments":true,"path":"ICLR21-ADV/","link":"","permalink":"https://tianlong-chen.github.io/ICLR21-ADV/","excerpt":"","text":"Robust Overfitting may be mitigated by properly learned smoothening[Paper] [Code] AbstractA recent study (Rice et al., 2020) revealed overfitting to be a dominant phenomenon in adversarially robust training of deep networks, and that appropriate early-stopping of adversarial training (AT) could match the performance gains of most recent algorithmic improvements. This intriguing problem of robust overfitting motivates us to seek more remedies. As a pilot study, this paper investigates two empirical means to inject more learned smoothening during AT: one leveraging knowledge distillation and self-training to smooth the logits, the other performing stochastic weight averaging (Izmailov et al., 2018) to smooth the weights. Despite the embarrassing simplicity, the two approaches are surprisingly effective and hassle-free in mitigating robust overfitting. Experiments demonstrate that by plugging in them to AT, we can simultaneously boost the standard accuracy by 3.72%6.68% and robust accuracy by 0.22%2 .03%, across multiple datasets (STL-10, SVHN, CIFAR-10, CIFAR-100, and Tiny ImageNet), perturbation types (ℓ∞ and ℓ2), and robustified methods (PGD, TRADES, and FSGM), establishing the new state-of-the-art bar in AT. We present systematic visualizations and analysis to dive into their possible working mechanisms. We also carefully exclude the possibility of gradient masking by evaluating our models’ robustness against transfer attacks.","categories":[{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"}],"tags":[{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Knowledge Distillation","slug":"Knowledge-Distillation","permalink":"https://tianlong-chen.github.io/tags/Knowledge-Distillation/"}]},{"title":"(ICLR 2021) Long Live the Lottery, The Existence of Winning Tickets in Lifelong Learning","slug":"ICLR-21-LifeLT","date":"2021-05-01T05:00:00.000Z","updated":"2021-02-08T02:10:03.561Z","comments":true,"path":"ICLR-21-LifeLT/","link":"","permalink":"https://tianlong-chen.github.io/ICLR-21-LifeLT/","excerpt":"","text":"Long Live the Lottery: The Existence of Winning Tickets in Lifelong Learning[Paper] [Code] AbstractThe lottery ticket hypothesis demonstrates that a highly sparsified sub-network can be trained in isolation, given the appropriate weight initialization. This paper extends that hypothesis from one-shot task leaning, and demonstrate for the first time that such extremely compact and independently trainable sub-networks can be also identified in the lifelong learning scenario, which we call lifelong tickets. We show that the resulting lifelong ticket can further be leveraged to improve the performance of learning over continual tasks. However, it is highly non-trivial to conduct network pruning in the lifelong setting. Two critical roadblocks arise: i) As many tasks now arrive sequentially, finding tickets in a greedy weight pruning fashion will inevitably suffer from the intrinsic bias, that the earlier emerging tasks impact more; ii) As lifelong learning is consistently challenged by catastrophic forgetting, the compact network capacity of tickets might amplify the risk of forgetting. In view of those, we introduce two pruning options, e.g., top-down and bottom-up, for finding lifelong tickets. Compared to the top-down pruning that extends vanilla (iterative) pruning over sequential tasks, we show that the bottom-up one, which can dynamically shrink and (re-)expand model capacity, effectively avoids the undesirable excessive pruning in the early stage. We additionally introduce lottery teaching that further overcomes forgetting via knowledge distillation aided by external unlabeled data. Unifying those ingredients, we demonstrate the existence of very competitive lifelong tickets, e.g., achieving 3-8% of the dense model size with even higher accuracy, compared to strong class-incremental learning baselines on CIFAR-10/CIFAR-100/Tiny-ImageNet datasets.","categories":[{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"}],"tags":[{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"Lifelong Learning","slug":"Lifelong-Learning","permalink":"https://tianlong-chen.github.io/tags/Lifelong-Learning/"}]},{"title":"(ICLR 2021) Long Live the Lottery, The Existence of Winning Tickets in Lifelong Learning","slug":"ICLR21-LifeLT","date":"2021-05-01T05:00:00.000Z","updated":"2021-02-08T02:18:35.833Z","comments":true,"path":"ICLR21-LifeLT/","link":"","permalink":"https://tianlong-chen.github.io/ICLR21-LifeLT/","excerpt":"","text":"Long Live the Lottery: The Existence of Winning Tickets in Lifelong Learning[Paper] [Code] AbstractThe lottery ticket hypothesis demonstrates that a highly sparsified sub-network can be trained in isolation, given the appropriate weight initialization. This paper extends that hypothesis from one-shot task leaning, and demonstrate for the first time that such extremely compact and independently trainable sub-networks can be also identified in the lifelong learning scenario, which we call lifelong tickets. We show that the resulting lifelong ticket can further be leveraged to improve the performance of learning over continual tasks. However, it is highly non-trivial to conduct network pruning in the lifelong setting. Two critical roadblocks arise: i) As many tasks now arrive sequentially, finding tickets in a greedy weight pruning fashion will inevitably suffer from the intrinsic bias, that the earlier emerging tasks impact more; ii) As lifelong learning is consistently challenged by catastrophic forgetting, the compact network capacity of tickets might amplify the risk of forgetting. In view of those, we introduce two pruning options, e.g., top-down and bottom-up, for finding lifelong tickets. Compared to the top-down pruning that extends vanilla (iterative) pruning over sequential tasks, we show that the bottom-up one, which can dynamically shrink and (re-)expand model capacity, effectively avoids the undesirable excessive pruning in the early stage. We additionally introduce lottery teaching that further overcomes forgetting via knowledge distillation aided by external unlabeled data. Unifying those ingredients, we demonstrate the existence of very competitive lifelong tickets, e.g., achieving 3-8% of the dense model size with even higher accuracy, compared to strong class-incremental learning baselines on CIFAR-10/CIFAR-100/Tiny-ImageNet datasets.","categories":[{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"}],"tags":[{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"Lifelong Learning","slug":"Lifelong-Learning","permalink":"https://tianlong-chen.github.io/tags/Lifelong-Learning/"}]},{"title":"(ICLR 2021) GANs Can Play Lottery Tickets Too","slug":"ICLR21-GAN","date":"2021-04-30T05:00:00.000Z","updated":"2021-02-08T02:18:33.311Z","comments":true,"path":"ICLR21-GAN/","link":"","permalink":"https://tianlong-chen.github.io/ICLR21-GAN/","excerpt":"","text":"GANs Can Play Lottery Tickets Too[Paper] [Code] AbstractDeep generative adversarial networks (GANs) have gained growing popularity in numerous scenarios, while usually suffer from high parameter complexities for resource-constrained real-world applications. However, the compression of GANs has less been explored. A few works show that heuristically applying compression techniques normally leads to unsatisfactory results, due to the notorious training instability (of GANs). In parallel, the lottery ticket hypothesis shows prevailing success on discriminative models, in locating sparse matching subnetworks capable of training in isolation to full model performance. In this work, we for the first time study the existence of such trainable matching subnetworks in deep GANs. For a range of GANs, we certainly find matching subnetworks at 67%-74% sparsity. We observe that with or without pruning discriminator has a minor effect on the existence and quality of matching subnetworks, while the initialization used in the discriminator plays a significant role. We then show the powerful transferability of these subnetworks to unseen tasks. Furthermore, extensive experimental results demonstrate that our found subnetworks substantially outperform previous state-of-the-art GAN compression approaches in both image generation (e.g. SNGAN) and image-to-image translation GANs (e.g. CycleGAN).","categories":[{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"}],"tags":[{"name":"Adversarial Learning","slug":"Adversarial-Learning","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Learning/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"Generative Adversarial Networks","slug":"Generative-Adversarial-Networks","permalink":"https://tianlong-chen.github.io/tags/Generative-Adversarial-Networks/"}]},{"title":"(ICLR 2021 Spotlight Oral) Undistillable, Making A Nasty Teacher That CANNOT teach students","slug":"ICLR21-NastyT","date":"2021-04-29T05:00:00.000Z","updated":"2021-02-08T01:57:29.270Z","comments":true,"path":"ICLR21-NastyT/","link":"","permalink":"https://tianlong-chen.github.io/ICLR21-NastyT/","excerpt":"","text":"Undistillable: Making A Nasty Teacher That CANNOT teach students[Paper] [Code] AbstractKnowledge Distillation (KD) is a widely used technique to transfer knowledge from pre-trained teacher models to (usually more lightweight) student models. However, in certain situations, this technique is more of a curse than a blessing. For instance, KD poses a potential risk of exposing intellectual properties (IPs): even if a trained machine learning model is released in ``black boxes’’ (e.g., as executable software or APIs without open-sourcing code), it can still be replicated by KD through imitating input-output behaviors. To prevent this unwanted effect of KD, this paper introduces and investigates a concept called Nasty Teacher: a specially trained teacher network that yields nearly the same performance as a normal one, but would significantly degrade the performance of student models learned by imitating it. We propose a simple yet effective algorithm to build the nasty teacher, called self-undermining knowledge distillation. Specifically, we aim to maximize the difference between the output of the nasty teacher and a normal pre-trained network. Extensive experiments on several datasets demonstrate that our method is effective on both standard KD and data-free KD, providing the desirable KD-immunity to model owners for the first time. We hope our preliminary study can draw more awareness and interest in this new practical problem of both social and legal importance.","categories":[{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"}],"tags":[{"name":"Knowledge Distillation","slug":"Knowledge-Distillation","permalink":"https://tianlong-chen.github.io/tags/Knowledge-Distillation/"},{"name":"Adversarial Learning","slug":"Adversarial-Learning","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Learning/"},{"name":"Privacy Preserving","slug":"Privacy-Preserving","permalink":"https://tianlong-chen.github.io/tags/Privacy-Preserving/"}]},{"title":"(ICLR 2021) Learning A Minimax Optimizer, A Pilot Study","slug":"ICLR21-L2O","date":"2021-04-28T05:00:00.000Z","updated":"2021-02-08T02:03:32.284Z","comments":true,"path":"ICLR21-L2O/","link":"","permalink":"https://tianlong-chen.github.io/ICLR21-L2O/","excerpt":"","text":"Learning A Minimax Optimizer: A Pilot Study[Paper] [Code] AbstractSolving continuous minimax optimization is of extensive practical interest, yet notoriously unstable and difficult. This paper introduces the learning to optimize (L2O) methodology to the minimax problems for the first time, and addresses its accompanying unique challenges. We first present Twin L2O, the first dedicated minimax L2O framework consisting of two LSTMs for updating min and max variables, respectively. That decoupled design is found to facilitate learning, particularly when the min and max variables are highly non-symmetric. Empirical experiments on a variety of minimax problems corroborates the effectiveness of Twin-L2O. We then discuss a crucial concern of Twin-L2O, i.e., its inevitably limited generalizability to unseen optimizees, and present two complementary strategies. Our first solution, Enhanced Twin-L2O, is empirically applicable for general minimax problems, by improving L2O training via leveraging curriculum learning. We extensively benchmark our algorithms on popular minimax problems, and compare against state-of-the-art minimax solvers. Our second alternative, called Safeguarded Twin L2O, is a preliminary theoretical exploration stating that under some strong assumptions, it is possible to theoretically establish the convergence of Twin-L2O on optimizing any unseen objective.","categories":[{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"}],"tags":[{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Curriculum Learning","slug":"Curriculum-Learning","permalink":"https://tianlong-chen.github.io/tags/Curriculum-Learning/"}]},{"title":"(ArXiv Preprint 2021) The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision Models","slug":"Preprint-LTH","date":"2021-03-15T05:00:00.000Z","updated":"2021-02-08T03:18:37.499Z","comments":true,"path":"Preprint-LTH/","link":"","permalink":"https://tianlong-chen.github.io/Preprint-LTH/","excerpt":"","text":"The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision Models[Paper] [Code] AbstractThe computer vision world has been re-gaining enthusiasm in various pre-trained models, including both classical ImageNet supervised pre-training and recently emerged self-supervised pre-training such as simCLR and MoCo. Pre-trained weights often boost a wide range of downstream tasks including classification, detection, and segmentation. Latest studies suggest that the pre-training benefits from gigantic model capacity. We are hereby curious and ask: after pre-training, does a pre-trained model indeed have to stay large for its universal downstream transferability?In this paper, we examine the supervised and self-supervised pre-trained models through the lens of lottery ticket hypothesis (LTH). LTH identifies highly sparse matching subnetworks that can be trained in isolation from (nearly) scratch, to reach the full models’ performance. We extend the scope of LTH to questioning whether matching subnetworks still exist in the pre-training models, that enjoy the same downstream transfer performance. Our extensive experiments convey an overall positive message: from all pre-trained weights obtained by ImageNet classification, simCLR and MoCo, we are consistently able to locate such matching subnetworks at 59.04% to 96.48% sparsity that transfer universally to multiple downstream tasks, whose performance see no degradation compared to using full pre-trained weights. Further analyses reveal that subnetworks found from different pre-training tend to yield diverse mask structures and perturbation sensitivities. We conclude that the core LTH observations remain generally relevant in the pre-training paradigm of computer vision, but more delicate discussions are needed in some cases.","categories":[{"name":"ArXiv Preprint","slug":"ArXiv-Preprint","permalink":"https://tianlong-chen.github.io/categories/ArXiv-Preprint/"}],"tags":[{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"Detection","slug":"Detection","permalink":"https://tianlong-chen.github.io/tags/Detection/"},{"name":"Segmentation","slug":"Segmentation","permalink":"https://tianlong-chen.github.io/tags/Segmentation/"}]},{"title":"(ICASSP 2021) VGAI, End-to-End Learning of Vision-Based Decentralized Controllers for Robot Swarms","slug":"ICASSP21","date":"2021-03-01T06:00:00.000Z","updated":"2021-02-08T03:01:40.761Z","comments":true,"path":"ICASSP21/","link":"","permalink":"https://tianlong-chen.github.io/ICASSP21/","excerpt":"","text":"VGAI: End-to-End Learning of Vision-Based Decentralized Controllers for Robot Swarms[Paper] [Code] AbstractDecentralized coordination of a robot swarm requires addressing the tension between local perceptions and actions, and the accomplishment of a global objective. In this work, we propose to learn decentralized controllers based on solely raw visual inputs. For the first time, that integrates the learning of two key components: communication and visual perception, in one end-to-end framework. More specifically, we consider that each robot has access to a visual perception of the immediate surroundings, and communication capabilities to transmit and receive messages from other neighboring robots. Our proposed learning framework combines a convolutional neural network (CNN) for each robot to extract messages from the visual inputs, and a graph neural network (GNN) over the entire swarm to transmit, receive and process these messages in order to decide on actions. The use of a GNN and locally-run CNNs results naturally in a decentralized controller. We jointly train the CNNs and the GNN so that each robot learns to extract messages from the images that are adequate for the team as a whole. Our experiments demonstrate the proposed architecture in the problem of drone flocking and show its promising performance and scalability, e.g., achieving successful decentralized flocking for large-sized swarms consisting of up to 75 drones.","categories":[{"name":"ICASSP'21","slug":"ICASSP-21","permalink":"https://tianlong-chen.github.io/categories/ICASSP-21/"}],"tags":[{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Imitation Training","slug":"Imitation-Training","permalink":"https://tianlong-chen.github.io/tags/Imitation-Training/"}]},{"title":"(AAAIW 2021 Oral) AR-Stock, Deep Augmented Relational Stock Prediction","slug":"AAAIW-21","date":"2021-01-07T06:00:00.000Z","updated":"2021-02-08T02:36:59.706Z","comments":true,"path":"AAAIW-21/","link":"","permalink":"https://tianlong-chen.github.io/AAAIW-21/","excerpt":"","text":"AR-Stock: Deep Augmented Relational Stock Prediction[Paper] [Code] AbstractStock prediction aims to assess future price trends and assist investment decisions. With the recent success of graph convolutional networks (GCNs) in modeling relational data, they have also shown promise for stock prediction. However, vanilla GCNs lack the ability to capture long-range dependencies in graphs and have not fully utilized the structured knowledge with data available. In this paper, we propose a novel framework of Deep Augmented Relational Stock Prediction (AR-Stock). We first detect the long-range links using pre-trained knowledge graph embeddings, leading to a new geometrically augmented edge type into the provided stock market graph. We then construct the GCN model on this augmented graph, that predicts each company’s stock prices by leveraging its related corporations; specifically, to train the GCNs better over this complex graph, we introduce two novel self-supervised regularizers (graph partition and graph completion) to inform the model with the global and local topology features. Unifying the above ingredients, AR-Stock has the unique strength in capturing long-term and hidden graph node dependencies. Experiments on two popular stock market datasets, NASDAQ and NYSE, demonstrate the prediction superiority of AR-Stock. Particularly, in terms of the investment return ratio, AR-Stock improves 65.77% in NASDAQ, and 30.48% in NYSE, over state-of-the-art models, respectively.","categories":[{"name":"AAAIW'21","slug":"AAAIW-21","permalink":"https://tianlong-chen.github.io/categories/AAAIW-21/"}],"tags":[{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"}]},{"title":"(ArXiv Preprint 2021) Good Students Play Big Lottery Better","slug":"Preprint-KDLTH","date":"2021-01-05T06:00:00.000Z","updated":"2021-02-08T03:30:21.367Z","comments":true,"path":"Preprint-KDLTH/","link":"","permalink":"https://tianlong-chen.github.io/Preprint-KDLTH/","excerpt":"","text":"Good Students Play Big Lottery Better[Paper] [Code] AbstractLottery ticket hypothesis suggests that a dense neural network contains a sparse sub-network that can match the test accuracy of the original dense net when trained in isolation from (the same) random initialization. However, the hypothesis failed to generalize to larger dense networks such as ResNet-50. As a remedy, recent studies demonstrate that a sparse sub-network can still be obtained by using a rewinding technique, which is to re-train it from early-phase training weights or learning rates of the dense model, rather than from random initialization.Is rewinding the only or the best way to scale up lottery tickets? This paper proposes a new, simpler and yet powerful technique for re-training the sub-network, called “Knowledge Distillation ticket” (KD ticket). Rewinding exploits the value of inheriting knowledge from the early training phase to improve lottery tickets in large networks. In comparison, KD ticket addresses a complementary possibility - inheriting useful knowledge from the late training phase of the dense model. It is achieved by leveraging the soft labels generated by the trained dense model to re-train the sub-network, instead of the hard labels. Extensive experiments are conducted using several large deep networks (e.g ResNet-50 and ResNet-110) on CIFAR-10 and ImageNet datasets. Without bells and whistles, when applied by itself, KD ticket performs on par or better than rewinding, while being nearly free of hyperparameters or ad-hoc selection. KD ticket can be further applied together with rewinding, yielding state-of-the-art results for large-scale lottery tickets.","categories":[{"name":"ArXiv Preprint","slug":"ArXiv-Preprint","permalink":"https://tianlong-chen.github.io/categories/ArXiv-Preprint/"}],"tags":[{"name":"Knowledge Distillation","slug":"Knowledge-Distillation","permalink":"https://tianlong-chen.github.io/tags/Knowledge-Distillation/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"}]},{"title":"(NeurIPS 2020 Spotlight Oral) Training Stronger Baselines for Learning to Optimize","slug":"NIPS20-L2O","date":"2020-12-06T06:00:00.000Z","updated":"2021-02-01T21:38:53.090Z","comments":true,"path":"NIPS20-L2O/","link":"","permalink":"https://tianlong-chen.github.io/NIPS20-L2O/","excerpt":"","text":"Training Stronger Baselines for Learning to Optimize[Paper] [Code] AbstractLearning to optimize (L2O) has gained increasing attention since classical optimizers require laborious problem-specific design and hyperparameter tuning. However, there is a gap between the practical demand and the achievable performance of existing L2O models. Specifically, those learned optimizers are applicable to only a limited class of problems, and often exhibit instability. With many efforts devoted to designing more sophisticated L2O models, we argue for another orthogonal, under-explored theme: the training techniques for those L2O models. We show that even the simplest L2O model could have been trained much better. We first present a progressive training scheme to gradually increase the optimizer unroll length, to mitigate a well-known L2O dilemma of truncation bias (shorter unrolling) versus gradient explosion (longer unrolling). We further leverage off-policy imitation learning to guide the L2O learning , by taking reference to the behavior of analytical optimizers. Our improved training techniques are plugged into a variety of state-of-the-art L2O models, and immediately boost their performance, without making any change to their model structures. Especially, by our proposed techniques, an earliest and simplest L2O model can be trained to outperform the latest complicated L2O models on a number of tasks. Our results demonstrate a greater potential of L2O yet to be unleashed, and urge to rethink the recent progress. The codes are publicly available at: https://github.com/VITA-Group/L2O-Training-Techniques.","categories":[{"name":"NeurIPS'20","slug":"NeurIPS-20","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-20/"}],"tags":[{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Curriculum Learning","slug":"Curriculum-Learning","permalink":"https://tianlong-chen.github.io/tags/Curriculum-Learning/"},{"name":"Imitation Learning","slug":"Imitation-Learning","permalink":"https://tianlong-chen.github.io/tags/Imitation-Learning/"}]},{"title":"(NeurIPS 2020) The Lottery Ticket Hypothesis for Pre-trained BERT Networks","slug":"NIPS20-BERT","date":"2020-12-05T06:00:00.000Z","updated":"2020-09-26T04:04:41.799Z","comments":true,"path":"NIPS20-BERT/","link":"","permalink":"https://tianlong-chen.github.io/NIPS20-BERT/","excerpt":"","text":"The Lottery Ticket Hypothesis for Pre-trained BERT Networks[Paper] [Code] AbstractIn natural language processing (NLP), enormous pre-trained models like BERT have become the standard starting point for training on a range of downstream tasks, and similar trends are emerging in other areas of deep learning. In parallel, work on the lottery ticket hypothesis has shown that models for NLP and computer vision contain smaller matching subnetworks capable of training in isolation to full accuracy and transferring to other tasks. In this work, we combine these observations to assess whether such trainable, transferrable subnetworks exist in pre-trained BERT models. For a range of downstream tasks, we indeed find matching subnetworks at 40% to 90% sparsity. We find these subnetworks at (pre-trained) initialization, a deviation from prior NLP research where they emerge only after some amount of training. Subnetworks found on the masked language modeling task (the same task used to pre-train the model) transfer universally; those found on other tasks transfer in a limited fashion if at all. As large-scale pre-training becomes an increasingly central paradigm in deep learning, our results demonstrate that the main lottery ticket observations remain relevant in this context. Codes available at https://github.com/VITA-Group/BERT-Tickets.","categories":[{"name":"NeurIPS'20","slug":"NeurIPS-20","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-20/"}],"tags":[{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://tianlong-chen.github.io/tags/Natural-Language-Processing/"},{"name":"BERT","slug":"BERT","permalink":"https://tianlong-chen.github.io/tags/BERT/"}]},{"title":"(NeurIPS 2020) Once-for-All Adversarial Training, In-Situ Trade off between Robustness and Accuracy for Free","slug":"NIPS20-CAT","date":"2020-12-04T06:00:00.000Z","updated":"2021-02-01T21:40:05.083Z","comments":true,"path":"NIPS20-CAT/","link":"","permalink":"https://tianlong-chen.github.io/NIPS20-CAT/","excerpt":"","text":"Once-for-All Adversarial Training: In-Situ Trade off between Robustness and Accuracy for Free[Paper] [Code] AbstractAdversarial training and its many variants substantially improve deep network robustness, yet at the cost of compromising standard accuracy. Moreover, the training process is heavy and hence it becomes impractical to thoroughly explore the trade-off between accuracy and robustness. This paper asks this new question: how to quickly calibrate a trained model in-situ, to examine the achievable trade-offs between its standard and robust accuracies, without (re-)training it many times? Our proposed framework, Calibratable Adversarial Training (CAT), is built on an innovative model-conditional training framework, with a controlling hyper-parameter as the input. The resulting model could be adjusted among different standard and robust accuracies “for free” at testing time. As an important knob, we exploit dual batch normalization to separate standard and adversarial feature statistics, so that they can be learned in one model without degrading performance. We further extend CAT to a Calibratable Adversarial Training and Slimming (CATS) framework, that allows for the joint trade-off among accuracy, robustness and runtime efficiency. Experiments show that, without any re-training nor ensembling, CAT/CATS achieve similar or even superior performance compared to dedicatedly trained models at various configurations. All codes and pretrained models will be released upon acceptance. The codes are publicly available at: https://github.com/VITA-Group/Once-for-All-Adversarial-Training.","categories":[{"name":"NeurIPS'20","slug":"NeurIPS-20","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-20/"}],"tags":[{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"Batch Normalization","slug":"Batch-Normalization","permalink":"https://tianlong-chen.github.io/tags/Batch-Normalization/"}]},{"title":"(NeurIPS 2020) Pre-Training Graph Neural Networks A Contrastive Learning Framework with Augmentations","slug":"NIPS20-GCNCL","date":"2020-12-03T06:00:00.000Z","updated":"2021-02-01T21:41:15.647Z","comments":true,"path":"NIPS20-GCNCL/","link":"","permalink":"https://tianlong-chen.github.io/NIPS20-GCNCL/","excerpt":"","text":"Pre-Training Graph Neural Networks: A Contrastive Learning Framework with Augmentations[Paper] [Code] AbstractGeneralizable, transferrable, and robust representation learning on graph-structured data remains a challenge for current graph neural networks (GNNs). Unlike what has been developed for convolutional neural networks (CNNs) for image data, self-supervised learning and pre-training are intrinsically difficult to pursue and indeed rarely explored for GNNs. In this paper, we propose a graph contrastive learning (GraphCL) framework to learn perturbation-invariant unsupervised representations of graph data. To this end, we first design four types of graph augmentations to incorporate various priors. Furthermore, we systematically assess, summarize, and rationalize the impact of contrasting various combinations of graph augmentations on various datasets, in the setting of semi-supervised, unsupervised, and transfer learning as well as adversarial attacks. The results show that, even without tuning augmentation extents nor using sophisticated GNN architectures, our GraphCL framework can produce graph representations of similar or better generalizability, transferrability, and robustness compared to state-of-the-art methods. We also investigate the impact of parameterized graph augmentation extents and patterns, and observe further performance gains in preliminary experiments. The codes are publicly available at:.","categories":[{"name":"NeurIPS'20","slug":"NeurIPS-20","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-20/"}],"tags":[{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Contrasive Learning","slug":"Contrasive-Learning","permalink":"https://tianlong-chen.github.io/tags/Contrasive-Learning/"},{"name":"Graph Augmentation","slug":"Graph-Augmentation","permalink":"https://tianlong-chen.github.io/tags/Graph-Augmentation/"}]},{"title":"(NeurIPS 2020) Adversarial Contrastive Learning, Harvesting More Robustness from Unsupervised Pre-Training","slug":"NIPS20-ADVCL","date":"2020-12-02T06:00:00.000Z","updated":"2021-02-08T01:02:58.473Z","comments":true,"path":"NIPS20-ADVCL/","link":"","permalink":"https://tianlong-chen.github.io/NIPS20-ADVCL/","excerpt":"","text":"Adversarial Contrastive Learning: Harvesting More Robustness from Unsupervised Pre-Training[Paper] [Code] AbstractRecent work has shown that, when integrated with adversarial training, self-supervised pre-training with several pretext tasks can lead to state-of-the-art robustness. In this work, we show that contrasting features to random and adversarial perturbations for consistency can benefit robustness-aware pre-training even further. Our approach leverages a recent contrastive learning framework, which learns representations by maximizing feature consistency under differently augmented views. This fits particularly well with the goal of adversarial robustness, as one cause of adversarial fragility is the lack of feature invariance, i.e., small input perturbations can result in undesirable large changes in features or even predicted labels. We explore various options to formulate the contrastive task, and demonstrate that by injecting adversarial augmentations, contrastive pre-training indeed contributes to learning data-efficient robust models. We extensively evaluate the proposed Adversarial Contrastive Learning (ACL) and show it can consistently outperform state-of-the-arts. For example on the CIFAR-10 dataset, ACL outperforms the latest unsupervised robust pre-training approach with substantial margins: 2.99% on robust accuracy and 2.14% on standard accuracy. We further demonstrate that ACL pre-training can improve semi-supervised adversarial training, even at very low label rates. The codes are publicly available at:.","categories":[{"name":"NeurIPS'20","slug":"NeurIPS-20","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-20/"}],"tags":[{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Contrasive Learning","slug":"Contrasive-Learning","permalink":"https://tianlong-chen.github.io/tags/Contrasive-Learning/"}]},{"title":"(InterSpeech 2020) AutoSpeech, Neural Architecture Search for Speaker Recognition","slug":"InterSpeech20","date":"2020-10-26T05:00:00.000Z","updated":"2020-09-26T23:42:56.400Z","comments":true,"path":"InterSpeech20/","link":"","permalink":"https://tianlong-chen.github.io/InterSpeech20/","excerpt":"","text":"AutoSpeech: Neural Architecture Search for Speaker Recognition[Paper] [Code] AbstractSpeaker recognition systems based on Convolutional Neural Networks (CNNs) are often built with off-the-shelf backbones such as VGG-Net or ResNet. However, these backbones were originally proposed for image classification, and therefore may not be naturally fit for speaker recognition. Due to the prohibitive complexity of manually exploring the design space, we propose the first neural architecture search approach approach for the speaker recognition tasks, named as AutoSpeech. Our algorithm first identifies the optimal operation combination in a neural cell and then derives a CNN model by stacking the neural cell for multiple times. The final speaker recognition model can be obtained by training the derived CNN model through the standard scheme. To evaluate the proposed approach, we conduct experiments on both speaker identification and speaker verification tasks using the VoxCeleb1 dataset. Results demonstrate that the derived CNN architectures from the proposed approach significantly outperform current speaker recognition systems based on VGG-M, ResNet-18, and ResNet-34 backbones, while enjoying lower model complexity.","categories":[{"name":"InterSpeech'20","slug":"InterSpeech-20","permalink":"https://tianlong-chen.github.io/categories/InterSpeech-20/"}],"tags":[{"name":"Speaker Recognition","slug":"Speaker-Recognition","permalink":"https://tianlong-chen.github.io/tags/Speaker-Recognition/"},{"name":"Neural Archtecture Search","slug":"Neural-Archtecture-Search","permalink":"https://tianlong-chen.github.io/tags/Neural-Archtecture-Search/"}]},{"title":"(ECCV 2020) HALO, Hardware-Aware Learning to Optimize","slug":"ECCV20-HALO","date":"2020-08-23T05:00:00.000Z","updated":"2020-09-26T23:42:00.702Z","comments":true,"path":"ECCV20-HALO/","link":"","permalink":"https://tianlong-chen.github.io/ECCV20-HALO/","excerpt":"","text":"HALO: Hardware-Aware Learning to Optimize[Paper] [Code] AbstractThere has been an explosive demand for bringing machine learning (ML) powered intelligence into numerous Internet-of-Things (IoT) devices. However, the effectiveness of such intelligent functionality requires in-situ continuous model adaptation for adapting to new dataand environments, while the on-device computing and energy resources are usually extremely constrained. Neither traditional hand-crafted (e.g., SGD, Adagrad, and Adam) nor existing meta optimizers are specifically designed to meet those challenges, as the former requires tedious hyper-parameter tuning while the latter are often costly due to themeta algorithms’ own overhead. To this end, we propose hardware-aware learning to optimize (HALO), a practical meta optimizer dedicated to resource-efficient on-device adaptation. Our HALO optimizer features the following highlights: (1) faster adaptation speed (i.e., taking fewer data oriterations to reach a specified accuracy) by introducing a new regularizer to promote empirical generalization; and (2) lower per-iteration complexity, thanks to a stochastic structural sparsity regularizer being enforced. Furthermore, the optimizer itself is designed as a very light-weight RNN and thus incurs negligible overhead. Ablation studies and experiments onfive datasets, six optimizees, and two state-of-the-art (SOTA) edge AIdevices validate that, while always achieving a better accuracy (↑0.46% -↑20.28%), HALO can greatly trim down the energy cost (up to↓60%) inadaptation, quantified using an IoT device or SOTA simulator. Codesand pre-trained models are at https://github.com/RICE-EIC/HALO .","categories":[{"name":"ECCV'20","slug":"ECCV-20","permalink":"https://tianlong-chen.github.io/categories/ECCV-20/"}],"tags":[{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Adaptation","slug":"Adaptation","permalink":"https://tianlong-chen.github.io/tags/Adaptation/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"}]},{"title":"(ICML 2020) When Does Self-Supervision Help Graph Convolutional Networks?","slug":"ICML20-GCN","date":"2020-07-12T05:00:00.000Z","updated":"2020-09-26T23:42:37.501Z","comments":true,"path":"ICML20-GCN/","link":"","permalink":"https://tianlong-chen.github.io/ICML20-GCN/","excerpt":"","text":"When Does Self-Supervision Help Graph Convolutional Networks?[Paper] [Code] AbstractSelf-supervision as an emerging technique has been employed to train convolutional neural networks (CNNs) for more transferrable, generalizable, and robust representation learning of images. Its introduction to graph convolutional networks (GCNs) operating on graph data is however rarely explored. In this study, we report the first systematic exploration and assessment of incorporating self-supervision into GCNs. We first elaborate three mechanisms to incorporate self-supervision into GCNs, analyze the limitations of pretraining &amp; finetuning and self-training, and proceed to focus on multi-task learning. Moreover, we propose to investigate threenovel self-supervised learning tasks for GCNs with theoretical rationales and numerical comparisons. Lastly, we further integrate multi-task self-supervision into graph adversarial training. Our results show that, with properly designed task forms and incorporation mechanisms, self-supervision benefits GCNs in gaining more generalizability and robustness. Our codes are available at https://github.com/Shen-Lab/SS-GCNs .","categories":[{"name":"ICML'20","slug":"ICML-20","permalink":"https://tianlong-chen.github.io/categories/ICML-20/"}],"tags":[{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"}]},{"title":"(ICML 2020) Self-PU, Self Boosted and Calibrated Positive-Unlabeled Training","slug":"ICML20-Self","date":"2020-07-11T05:00:00.000Z","updated":"2020-09-26T23:42:46.634Z","comments":true,"path":"ICML20-Self/","link":"","permalink":"https://tianlong-chen.github.io/ICML20-Self/","excerpt":"","text":"Self-PU: Self Boosted and Calibrated Positive-Unlabeled Training[Paper] [Code] AbstractMany real-world applications have to tackle the Positive-Unlabeled (PU) learning problem,i.e.,learning binary classifiers from a large amountof unlabeled data and a few labeled positive examples. While current state-of-the-art methodsemploy importance reweighting to design various risk estimators, they ignored the learning capability of the model itself, which could haveprovided reliable supervision. This motivatesus to propose a novel Self-PU learning framework, which seamlessly integrates PU learningand self-training. Self-PU highlights three “self”-oriented building blocks: a self-paced training algorithm that adaptively discovers and augments confident positive/negative examples as the training proceeds; a self-calibrated instance-aware loss; and a self-distillation scheme that introduces teacher-students learning as an effectiveregularization for PU learning. We demonstratethe state-of-the-art performance of Self-PU oncommon PU learning benchmarks (MNIST and CIFAR-10), which compare favorably against thelatest competitors. Moreover, we study a real-world application of PU learning,i.e., classifying brain images of Alzheimer’s Disease. Self-PU obtains significantly improved results on the renowned Alzheimer’s Disease Neuroimaging Initiative (ADNI) database over existing methods.","categories":[{"name":"ICML'20","slug":"ICML-20","permalink":"https://tianlong-chen.github.io/categories/ICML-20/"}],"tags":[{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"PU Learning","slug":"PU-Learning","permalink":"https://tianlong-chen.github.io/tags/PU-Learning/"},{"name":"Self Training","slug":"Self-Training","permalink":"https://tianlong-chen.github.io/tags/Self-Training/"}]},{"title":"(CVPR 2020) Adversarial Robustness, From Self-Supervised Pre-Training to Fine-Tuning","slug":"CVPR20-Selfie","date":"2020-06-18T05:00:00.000Z","updated":"2020-07-22T04:15:58.249Z","comments":true,"path":"CVPR20-Selfie/","link":"","permalink":"https://tianlong-chen.github.io/CVPR20-Selfie/","excerpt":"","text":"Adversarial Robustness: From Self-Supervised Pre-Training to Fine-Tuning[Paper] [Code] AbstractPretrained models from self-supervision are prevalently used in fine-tuning downstream tasks faster or for better accuracy. However, gaining robustness from pretraining is left unexplored. We introduce adversarial training into self- supervision, to provide general-purpose robust pretrained models for the first time. We find these robust pretrained models can benefit the subsequent fine-tuning in two ways: i) boosting final model robustness; ii) saving the computation cost, if proceeding towards adversarial fine-tuning. We conduct extensive experiments to demonstrate that the proposed framework achieves large performance margins (e.g., 3.83% on robust accuracy and 1.3% on standard accuracy, on the CIFAR-10 dataset), compared with the conventional end-to-end adversarial training baseline. Moreover, we find that different self-supervised pretrained models have diverse adversarial vulnerability. It inspires us to ensemble several pretraining tasks, which boosts robustness more. Our ensemble strategy contributes to a further improvement of 3.59% on robust accuracy, while maintaining a slightly higher standard accuracy on CIFAR-10. Our codes are available at https://github.com/TAMU-VITA/Adv-SS-Pretraining .","categories":[{"name":"CVPR'20","slug":"CVPR-20","permalink":"https://tianlong-chen.github.io/categories/CVPR-20/"}],"tags":[{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"}]},{"title":"(CVPR 2020) L^2-GCN, Layer-Wise and Learned Efficient Training of Graph Convolutional Networks","slug":"CVPR20-GCN","date":"2020-06-17T05:00:00.000Z","updated":"2020-09-26T23:41:47.642Z","comments":true,"path":"CVPR20-GCN/","link":"","permalink":"https://tianlong-chen.github.io/CVPR20-GCN/","excerpt":"","text":"L$^2$-GCN: Layer-Wise and Learned Efficient Training of Graph Convolutional Networks[Paper] [Code] AbstractGraph convolution networks (GCN) are increasingly popular in many applications, yet remain notoriously hard to train over large graph datasets. They need to compute node representations recursively from their neighbors. Current GCN training algorithms suffer from either high computational costs that grow exponentially with the number of layers, or high memory usage for loading the entire graph and node embeddings. In this paper, we propose a novel efficient layer-wise training framework for GCN (L-GCN), that disentangles feature aggregation and feature transformation during training, hence greatly reducing time and memory complexities. We present theoretical analysis for L-GCN under the graph isomorphism framework, that L-GCN leads to as powerful GCNs as the more costly conventional training algorithm does, under mild conditions. We further propose L$^2$-GCN, which learns a controller for each layer that can automatically adjust the training epochs per layer in L-GCN. Experiments show that L-GCN is faster than state-of-the-arts by at least an order of magnitude, with a consistent of memory usage not dependent on dataset size, while maintaining comparable prediction performance. With the learned controller, L$^2$-GCN can further cut the training time in half. Our codes are available at https://github.com/Shen-Lab/L2-GCN .","categories":[{"name":"CVPR'20","slug":"CVPR-20","permalink":"https://tianlong-chen.github.io/categories/CVPR-20/"}],"tags":[{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"}]},{"title":"(CVPRW 2020) Focus Longer to See Better, Recursively Refined Attention for Fine-Grained Image Classification","slug":"CVPRW20","date":"2020-06-16T05:00:00.000Z","updated":"2020-08-20T03:31:23.737Z","comments":true,"path":"CVPRW20/","link":"","permalink":"https://tianlong-chen.github.io/CVPRW20/","excerpt":"","text":"Focus Longer to See Better: Recursively Refined Attention for Fine-Grained Image Classification[Paper] [Code] AbstractDeep Neural Network has shown great strides in the coarse-grained image classification task. It was in part due to its strong ability to extract discriminative feature representations from the images. However, the marginal visual difference between different classes in fine-grained images makes this very task harder. In this paper, we tried to focus on these marginal differences to extract more representative features. Similar to human vision, our network repetitively focuses on parts of images to spot small discriminative parts among the classes. Moreover, we show through interpretability techniques how our network focus changes from coarse to fine details. Through our experiments, we also show that a simple attention model can aggregate (weighted) these finer details to focus on the most dominant discriminative part of the image. Our network uses only image-level labels and does not need bounding box/part annotation information. Further, the simplicity of our network makes it an easy plug-n-play module. Apart from providing interpretability, our network boosts the performance (up to 2%) when compared to its baseline counterparts. Our codebase is available at https://github.com/TAMU-VITA/Focus-Longer-to-See-Better .","categories":[{"name":"CVPRW'20","slug":"CVPRW-20","permalink":"https://tianlong-chen.github.io/categories/CVPRW-20/"}],"tags":[{"name":"Attention","slug":"Attention","permalink":"https://tianlong-chen.github.io/tags/Attention/"},{"name":"Fine-Grained Classification","slug":"Fine-Grained-Classification","permalink":"https://tianlong-chen.github.io/tags/Fine-Grained-Classification/"}]},{"title":"(ArXiv Preprint 2020) Can 3D Adversarial Logos Cloak Humans?","slug":"Preprint-ADV","date":"2020-06-15T05:00:00.000Z","updated":"2020-08-18T01:33:03.938Z","comments":true,"path":"Preprint-ADV/","link":"","permalink":"https://tianlong-chen.github.io/Preprint-ADV/","excerpt":"","text":"Can 3D Adversarial Logos Cloak Humans?[Paper] [Code] AbstractWith the trend of adversarial attacks, researchers attempt to fool trained object detectors in 2D scenes. Among many of them, an intriguing new form of attack with potential real-world usage is to append adversarial patches (e.g. logos) to images. Nevertheless, much less have we known about adversarial attacks from 3D rendering views, which is essential for the attack to be persistently strong in the physical world. This paper presents a new 3D adversarial logo attack: we construct an arbitrary shape logo from a 2D texture image and map this image into a 3D adversarial logo via a texture mapping called logo transformation. The resulting 3D adversarial logo is then viewed as an adversarial texture enabling easy manipulation of its shape and position. This greatly extends the versatility of adversarial training for computer graphics synthesized imagery. Contrary to the traditional adversarial patch, this new form of attack is mapped into the 3D object world and back-propagates to the 2D image domain through differentiable rendering. In addition, and unlike existing adversarial patches, our new 3D adversarial logo is shown to fool state-of-the-art deep object detectors robustly under model rotations, leading to one step further for realistic attacks in the physical world. Our codes are available at https://github.com/TAMU-VITA/3D_Adversarial_Logo .","categories":[{"name":"ArXiv Preprint","slug":"ArXiv-Preprint","permalink":"https://tianlong-chen.github.io/categories/ArXiv-Preprint/"}],"tags":[{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Detection","slug":"Detection","permalink":"https://tianlong-chen.github.io/tags/Detection/"},{"name":"3D Mesh","slug":"3D-Mesh","permalink":"https://tianlong-chen.github.io/tags/3D-Mesh/"}]},{"title":"(LREC 2020) Dataset and Enhanced Model for Eligibility Criteria-to-SQL Semantic Parsing","slug":"LREC20","date":"2020-05-11T05:00:00.000Z","updated":"2020-07-22T02:41:25.345Z","comments":true,"path":"LREC20/","link":"","permalink":"https://tianlong-chen.github.io/LREC20/","excerpt":"","text":"Dataset and Enhanced Model for Eligibility Criteria-to-SQL Semantic Parsing[Paper] AbstractClinical trials often require that patients meet eligibility criteria (e.g., have specific conditions) to ensure the safety and the effectiveness of studies. However, retrieving eligible patients for a trial from the electronic health record (EHR) database remains a challenging task for clinicians since it requires not only medical knowledge about eligibility criteria, but also an adequate understanding of structured query language (SQL). In this paper, we introduce a new dataset that includes the first-of-its-kind eligibility-criteria corpus and the corresponding queries for criteria-to-sql (Criteria2SQL), a task translating the eligibility criteria to executable SQL queries. Compared to existing datasets, the queries in the dataset here are derived from the eligibility criteria of clinical trials and include Order-sensitive, Counting-based, and Boolean-type cases which are not seen before. In addition to the dataset, we propose a novel neural semantic parser as a strong baseline model. Extensive experiments show that the proposed parser outperforms existing state-of-the-art general-purpose text-to-sql models while highlighting the challenges presented by the new dataset. The uniqueness and the diversity of the dataset leave a lot of research opportunities for future improvement.","categories":[{"name":"LREC'20","slug":"LREC-20","permalink":"https://tianlong-chen.github.io/categories/LREC-20/"}],"tags":[{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://tianlong-chen.github.io/tags/Natural-Language-Processing/"},{"name":"BERT","slug":"BERT","permalink":"https://tianlong-chen.github.io/tags/BERT/"}]},{"title":"(ICLR 2020) Triple Wins, Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference","slug":"ICLR20-Triple","date":"2020-05-05T05:00:00.000Z","updated":"2020-09-26T23:42:26.760Z","comments":true,"path":"ICLR20-Triple/","link":"","permalink":"https://tianlong-chen.github.io/ICLR20-Triple/","excerpt":"","text":"Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference[Paper] [Code] AbstractDeep networks were recently suggested to face the odds between accuracy (on clean natural images) and robustness (on adversarially perturbed images) (Tsipras et al., 2019). Such a dilemma is shown to be rooted in the inherently higher sample complexity (Schmidt et al., 2018) and/or model capacity (Nakkiran, 2019), for learning a high-accuracy and robust classifier. In view of that, give a classification task, growing the model capacity appears to help draw a win-win between accuracy and robustness, yet at the expense of model size and latency, therefore posing challenges for resource-constrained applications. Is it possible to co-design model accuracy, robustness and efficiency to achieve their triple wins? This paper studies multi-exit networks associated with input-adaptive efficient inference, showing their strong promise in achieving a “sweet point” in co- optimizing model accuracy, robustness and efficiency. Our proposed solution, dubbed Robust Dynamic Inference Networks (RDI-Nets), allows for each input (either clean or adversarial) to adaptively choose one of the multiple output layers (early branches or the final one) to output its prediction. That multi-loss adaptivity adds new variations and flexibility to adversarial attacks and defenses, on which we present a systematical investigation. We show experimentally that by equipping existing backbones with such robust adaptive inference, the resulting RDI-Nets can achieve better accuracy and robustness, yet with over 30% computational savings, compared to the defended original models.","categories":[{"name":"ICLR'20","slug":"ICLR-20","permalink":"https://tianlong-chen.github.io/categories/ICLR-20/"}],"tags":[{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"Adaptive Inference","slug":"Adaptive-Inference","permalink":"https://tianlong-chen.github.io/tags/Adaptive-Inference/"}]},{"title":"(ICLR 2020) I am Going MAD, Maximum Discrepancy Competition for Comparing Classifiers Adaptively","slug":"ICLR20-MAD","date":"2020-05-04T05:00:00.000Z","updated":"2020-07-22T06:35:51.621Z","comments":true,"path":"ICLR20-MAD/","link":"","permalink":"https://tianlong-chen.github.io/ICLR20-MAD/","excerpt":"","text":"I am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively[Paper] [Code] AbstractThe learning of hierarchical representations for image classification has experienced an impressive series of successes due in part to the availability of large-scale labeled data for training. On the other hand, the trained classifiers have traditionally been evaluated on small and fixed sets of test images, which are deemed to be extremely sparsely distributed in the space of all natural images. It is thus questionable whether recent performance improvements on the excessively re-used test sets generalize to real-world natural images with much richer content variations. Inspired by efficient stimulus selection for testing perceptual models in psychophysical and physiological studies, we present an alternative framework for comparing image classifiers, which we name the MAximum Discrepancy (MAD) competition. Rather than comparing image classifiers using fixed test images, we adaptively sample a small test set from an arbitrarily large corpus of unlabeled images so as to maximize the discrepancies between the classifiers, measured by the distance over WordNet hierarchy. Human labeling on the resulting model-dependent image sets reveals the relative performance of the competing classifiers, and provides useful insights on potential ways to improve them. We report the MAD competition results of eleven ImageNet classifiers while noting that the framework is readily extensible and cost-effective to add future classifiers into the competition. Codes can be found at https://github.com/TAMU-VITA/MAD .","categories":[{"name":"ICLR'20","slug":"ICLR-20","permalink":"https://tianlong-chen.github.io/categories/ICLR-20/"}],"tags":[{"name":"Model Comparison","slug":"Model-Comparison","permalink":"https://tianlong-chen.github.io/tags/Model-Comparison/"}]},{"title":"(WACV 2020) Calibrated Domain-Invariant Learning for Highly Generalizable Large Scale Re-Identification","slug":"WACV20","date":"2020-03-01T06:00:00.000Z","updated":"2020-07-22T07:38:53.093Z","comments":true,"path":"WACV20/","link":"","permalink":"https://tianlong-chen.github.io/WACV20/","excerpt":"","text":"Calibrated Domain-Invariant Learning for Highly Generalizable Large Scale Re-Identification[Paper] [Code] AbstractMany real-world applications, such as city scale traffic monitoring and control, requires large scale re-identification. However, previous ReID methods often failed to address two limitations in existing ReID benchmarks, i.e., low spatiotemporal coverage and sample imbalance. Notwithstanding their demonstrated success in every single benchmark, they have difficulties in generalizing to unseen environments. As a re∂sult, these methods are less applicable in a large scale setting due to poor generalization. In seek for a highly generaliz- able large-scale ReID method, we present an adversarial domain-invariant feature learning framework (ADIN) that explicitly learns to separate identity-related features from challenging variations, where for the first time “free” anno- tations in ReID data such as video timestamp and camera index are utilized. Furthermore, we find that the imbalance of nuisance classes jeopardizes the adversarial training, and for mitigation we propose a calibrated adversarial loss that is attentive to nuisance distribution. Experiments on existing large-scale person/vehicle ReID datasets demonstrate that ADIN learns more robust and generalizable representations, as evidenced by its outstanding direct transfer performance across datasets, which is a criterion that can better measure the generalizability of large scale Re-ID methods.","categories":[{"name":"WACV'20","slug":"WACV-20","permalink":"https://tianlong-chen.github.io/categories/WACV-20/"}],"tags":[{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"Person Re-Identification","slug":"Person-Re-Identification","permalink":"https://tianlong-chen.github.io/tags/Person-Re-Identification/"},{"name":"Adversarial Learning","slug":"Adversarial-Learning","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Learning/"}]},{"title":"(NeurIPS 2019) Learning to Optimize in Swarms","slug":"NIPS19","date":"2019-12-06T06:00:00.000Z","updated":"2020-07-22T06:33:33.991Z","comments":true,"path":"NIPS19/","link":"","permalink":"https://tianlong-chen.github.io/NIPS19/","excerpt":"","text":"Learning to Optimize in Swarms[Paper] [Code] AbstractLearning to optimize has emerged as a powerful framework for various optimization and machine learning tasks. Current such “meta-optimizers” often learn in the space of continuous optimization algorithms that are point-based and uncertainty- unaware. To overcome the limitations, we propose a meta-optimizer that learns in the algorithmic space of both point-based and population-based optimization algorithms. The meta-optimizer targets at a meta-loss function consisting of both cumulative regret and entropy. Specifically, we learn and interpret the update formula through a population of LSTMs embedded with sample- and feature-level attentions. Meanwhile, we estimate the posterior directly over the global optimum and use an uncertainty measure to help guide the learning process. Empirical results over non-convex test functions and the protein-docking application demonstrate that this new meta-optimizer outperforms existing competitors. The codes are publicly available at: https://github.com/Shen-Lab/LOIS.","categories":[{"name":"NeurIPS'19","slug":"NeurIPS-19","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-19/"}],"tags":[{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Attention","slug":"Attention","permalink":"https://tianlong-chen.github.io/tags/Attention/"}]},{"title":"(ICCV 2019) ABD-Net, Attentive but Diverse Person Re-Identification.","slug":"ICCV19-ABD","date":"2019-10-27T05:00:00.000Z","updated":"2020-07-22T06:30:09.827Z","comments":true,"path":"ICCV19-ABD/","link":"","permalink":"https://tianlong-chen.github.io/ICCV19-ABD/","excerpt":"","text":"ABD-Net: Attentive but Diverse Person Re-Identification[Paper] [Code] AbstractAttention mechanisms have been found effective for person re-identification (Re-ID). However, the learned “attentive” features are often not naturally uncorrelated or “diverse”, which compromises the retrieval performance based on the Euclidean distance. We advocate the com- plementary powers of attention and diversity for Re-ID, by proposing an Attentive but Diverse Network (ABD-Net). ABD-Net seamlessly integrates attention modules and diversity regularizations throughout the entire network to learn features that are representative, robust, and more dis- criminative. Specifically, we introduce a pair of comple- mentary attention modules, focusing on channel aggregation and position awareness, respectively. Then, we plug in a novel orthogonality constraint that efficiently enforces di- versity on both hidden activations and weights. Through an extensive set of ablation study, we verify that the attentive and diverse terms each contributes to the perfor- mance boosts of ABD-Net. It consistently outperforms exist- ing state-of-the-art methods on there popular person Re-ID benchmarks.","categories":[{"name":"ICCV'19","slug":"ICCV-19","permalink":"https://tianlong-chen.github.io/categories/ICCV-19/"}],"tags":[{"name":"Attention","slug":"Attention","permalink":"https://tianlong-chen.github.io/tags/Attention/"},{"name":"Person Re-Identification","slug":"Person-Re-Identification","permalink":"https://tianlong-chen.github.io/tags/Person-Re-Identification/"}]},{"title":"(ICCVW 2019) Cross-Model Person Search, A Coarse-to-FineFramework using Bi-directional Text-Image Matching","slug":"ICCVW19","date":"2019-10-26T05:00:00.000Z","updated":"2020-09-26T23:42:13.120Z","comments":true,"path":"ICCVW19/","link":"","permalink":"https://tianlong-chen.github.io/ICCVW19/","excerpt":"","text":"Cross-Model Person Search: A Coarse-to-FineFramework using Bi-directional Text-Image Matching[Paper] AbstractSearching person images from a gallery based on natu- ral language descriptions remains to be a challenging and under-explored cross-modal retrieval problem. To improve the accuracy off an image-based retrieval task, e.g., person re-identification (Person Re-Id), re-ranking is known to be an effective post-processing tool. In this paper, we extend re-ranking from uni-modal retrieval to cross-modal retrieval for the first time, and develop a bi-directional coarse-to-fine framework (BCF) for cross-modal person search. Built on a recent state-of-the-art Person Re- Id model , BCF exploits first text-to-image and then image-to-text relevance, in a two-stage refinement fash- ion. BCF ranks competitively against a strong baseline on the newly-introduced WIDER Person Search dataset , boosting validation set performance by 9.01% (top-1) / 3.87 % (mAP) for val1 and 6.60% (top-1) / 3.49% (mAP) for val2, respectively. With a high score, our solution ranks competitively in the ICCV 2019 WIDER Person Search by Language Challenge.","categories":[{"name":"ICCVW'19","slug":"ICCVW-19","permalink":"https://tianlong-chen.github.io/categories/ICCVW-19/"}],"tags":[{"name":"Person Re-Identification","slug":"Person-Re-Identification","permalink":"https://tianlong-chen.github.io/tags/Person-Re-Identification/"},{"name":"Multi-Modality","slug":"Multi-Modality","permalink":"https://tianlong-chen.github.io/tags/Multi-Modality/"}]}],"categories":[{"name":"ICLR'21","slug":"ICLR-21","permalink":"https://tianlong-chen.github.io/categories/ICLR-21/"},{"name":"ArXiv Preprint","slug":"ArXiv-Preprint","permalink":"https://tianlong-chen.github.io/categories/ArXiv-Preprint/"},{"name":"ICASSP'21","slug":"ICASSP-21","permalink":"https://tianlong-chen.github.io/categories/ICASSP-21/"},{"name":"AAAIW'21","slug":"AAAIW-21","permalink":"https://tianlong-chen.github.io/categories/AAAIW-21/"},{"name":"NeurIPS'20","slug":"NeurIPS-20","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-20/"},{"name":"InterSpeech'20","slug":"InterSpeech-20","permalink":"https://tianlong-chen.github.io/categories/InterSpeech-20/"},{"name":"ECCV'20","slug":"ECCV-20","permalink":"https://tianlong-chen.github.io/categories/ECCV-20/"},{"name":"ICML'20","slug":"ICML-20","permalink":"https://tianlong-chen.github.io/categories/ICML-20/"},{"name":"CVPR'20","slug":"CVPR-20","permalink":"https://tianlong-chen.github.io/categories/CVPR-20/"},{"name":"CVPRW'20","slug":"CVPRW-20","permalink":"https://tianlong-chen.github.io/categories/CVPRW-20/"},{"name":"LREC'20","slug":"LREC-20","permalink":"https://tianlong-chen.github.io/categories/LREC-20/"},{"name":"ICLR'20","slug":"ICLR-20","permalink":"https://tianlong-chen.github.io/categories/ICLR-20/"},{"name":"WACV'20","slug":"WACV-20","permalink":"https://tianlong-chen.github.io/categories/WACV-20/"},{"name":"NeurIPS'19","slug":"NeurIPS-19","permalink":"https://tianlong-chen.github.io/categories/NeurIPS-19/"},{"name":"ICCV'19","slug":"ICCV-19","permalink":"https://tianlong-chen.github.io/categories/ICCV-19/"},{"name":"ICCVW'19","slug":"ICCVW-19","permalink":"https://tianlong-chen.github.io/categories/ICCVW-19/"}],"tags":[{"name":"Adversarial Robustness","slug":"Adversarial-Robustness","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Robustness/"},{"name":"Knowledge Distillation","slug":"Knowledge-Distillation","permalink":"https://tianlong-chen.github.io/tags/Knowledge-Distillation/"},{"name":"Transfer Learning","slug":"Transfer-Learning","permalink":"https://tianlong-chen.github.io/tags/Transfer-Learning/"},{"name":"The Lottery Tickets Hypothesis","slug":"The-Lottery-Tickets-Hypothesis","permalink":"https://tianlong-chen.github.io/tags/The-Lottery-Tickets-Hypothesis/"},{"name":"Model Compression","slug":"Model-Compression","permalink":"https://tianlong-chen.github.io/tags/Model-Compression/"},{"name":"Lifelong Learning","slug":"Lifelong-Learning","permalink":"https://tianlong-chen.github.io/tags/Lifelong-Learning/"},{"name":"Adversarial Learning","slug":"Adversarial-Learning","permalink":"https://tianlong-chen.github.io/tags/Adversarial-Learning/"},{"name":"Generative Adversarial Networks","slug":"Generative-Adversarial-Networks","permalink":"https://tianlong-chen.github.io/tags/Generative-Adversarial-Networks/"},{"name":"Privacy Preserving","slug":"Privacy-Preserving","permalink":"https://tianlong-chen.github.io/tags/Privacy-Preserving/"},{"name":"Learning to Optimize","slug":"Learning-to-Optimize","permalink":"https://tianlong-chen.github.io/tags/Learning-to-Optimize/"},{"name":"Curriculum Learning","slug":"Curriculum-Learning","permalink":"https://tianlong-chen.github.io/tags/Curriculum-Learning/"},{"name":"Pre-Training","slug":"Pre-Training","permalink":"https://tianlong-chen.github.io/tags/Pre-Training/"},{"name":"Efficient Inference","slug":"Efficient-Inference","permalink":"https://tianlong-chen.github.io/tags/Efficient-Inference/"},{"name":"Detection","slug":"Detection","permalink":"https://tianlong-chen.github.io/tags/Detection/"},{"name":"Segmentation","slug":"Segmentation","permalink":"https://tianlong-chen.github.io/tags/Segmentation/"},{"name":"Graph Neural Networks","slug":"Graph-Neural-Networks","permalink":"https://tianlong-chen.github.io/tags/Graph-Neural-Networks/"},{"name":"Imitation Training","slug":"Imitation-Training","permalink":"https://tianlong-chen.github.io/tags/Imitation-Training/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"https://tianlong-chen.github.io/tags/Semi-Supervised-Learning/"},{"name":"Self-Supervision","slug":"Self-Supervision","permalink":"https://tianlong-chen.github.io/tags/Self-Supervision/"},{"name":"Imitation Learning","slug":"Imitation-Learning","permalink":"https://tianlong-chen.github.io/tags/Imitation-Learning/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://tianlong-chen.github.io/tags/Natural-Language-Processing/"},{"name":"BERT","slug":"BERT","permalink":"https://tianlong-chen.github.io/tags/BERT/"},{"name":"Efficient Training","slug":"Efficient-Training","permalink":"https://tianlong-chen.github.io/tags/Efficient-Training/"},{"name":"Batch Normalization","slug":"Batch-Normalization","permalink":"https://tianlong-chen.github.io/tags/Batch-Normalization/"},{"name":"Contrasive Learning","slug":"Contrasive-Learning","permalink":"https://tianlong-chen.github.io/tags/Contrasive-Learning/"},{"name":"Graph Augmentation","slug":"Graph-Augmentation","permalink":"https://tianlong-chen.github.io/tags/Graph-Augmentation/"},{"name":"Speaker Recognition","slug":"Speaker-Recognition","permalink":"https://tianlong-chen.github.io/tags/Speaker-Recognition/"},{"name":"Neural Archtecture Search","slug":"Neural-Archtecture-Search","permalink":"https://tianlong-chen.github.io/tags/Neural-Archtecture-Search/"},{"name":"Adaptation","slug":"Adaptation","permalink":"https://tianlong-chen.github.io/tags/Adaptation/"},{"name":"PU Learning","slug":"PU-Learning","permalink":"https://tianlong-chen.github.io/tags/PU-Learning/"},{"name":"Self Training","slug":"Self-Training","permalink":"https://tianlong-chen.github.io/tags/Self-Training/"},{"name":"Attention","slug":"Attention","permalink":"https://tianlong-chen.github.io/tags/Attention/"},{"name":"Fine-Grained Classification","slug":"Fine-Grained-Classification","permalink":"https://tianlong-chen.github.io/tags/Fine-Grained-Classification/"},{"name":"3D Mesh","slug":"3D-Mesh","permalink":"https://tianlong-chen.github.io/tags/3D-Mesh/"},{"name":"Adaptive Inference","slug":"Adaptive-Inference","permalink":"https://tianlong-chen.github.io/tags/Adaptive-Inference/"},{"name":"Model Comparison","slug":"Model-Comparison","permalink":"https://tianlong-chen.github.io/tags/Model-Comparison/"},{"name":"Person Re-Identification","slug":"Person-Re-Identification","permalink":"https://tianlong-chen.github.io/tags/Person-Re-Identification/"},{"name":"Multi-Modality","slug":"Multi-Modality","permalink":"https://tianlong-chen.github.io/tags/Multi-Modality/"}]}